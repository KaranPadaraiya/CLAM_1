{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKgCEN-G5Ko4"
      },
      "source": [
        "### **CLAM** **IMPLEMENTATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPqNE6LV42Rt"
      },
      "source": [
        "Clone CLAM GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QwW-Va2bIBNw",
        "outputId": "4acb10ac-2035-4987-80ec-358897efb2d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'CLAM'...\n",
            "remote: Enumerating objects: 714, done.\u001b[K\n",
            "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 714 (delta 55), reused 75 (delta 46), pack-reused 602\u001b[K\n",
            "Receiving objects: 100% (714/714), 46.92 MiB | 19.20 MiB/s, done.\n",
            "Resolving deltas: 100% (341/341), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mahmoodlab/CLAM.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juszM1xcIgX_",
        "outputId": "2a7c8604-c0ba-42a1-ed28-cb5f3932c55a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/CLAM\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/CLAM\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkGr16nW5DSo"
      },
      "source": [
        "Install Dependet liberaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yI4uYBlgIy11",
        "outputId": "1c24333b-9214-4caa-cbbe-05eb3433ed9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting timm==0.9.8\n",
            "  Downloading timm-0.9.8-py3-none-any.whl.metadata (59 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/59.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.3/59.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm==0.9.8) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.9.8) (0.18.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.8) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.8) (0.23.5)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.8) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.8) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.8) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.8) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.8) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.8) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.8) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.7->timm==0.9.8)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.7->timm==0.9.8)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.7->timm==0.9.8)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.7->timm==0.9.8)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.7->timm==0.9.8)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.7->timm==0.9.8)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.7->timm==0.9.8)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.7->timm==0.9.8)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.7->timm==0.9.8)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.7->timm==0.9.8)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.7->timm==0.9.8)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.8) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7->timm==0.9.8)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.8) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.8) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.8) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.9.8) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.9.8) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm==0.9.8) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.8) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.8) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.8) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.8) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm==0.9.8) (1.3.0)\n",
            "Downloading timm-0.9.8-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 timm-0.9.8\n"
          ]
        }
      ],
      "source": [
        "%pip install timm==0.9.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eABU_s9iI3K6",
        "outputId": "237af4da-686f-4e19-c21d-cb0d8a9453d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: torch==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.3.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1->torchvision) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.1->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (6.0.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Collecting openslide-python\n",
            "  Downloading openslide-python-1.3.1.tar.gz (358 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m359.0/359.0 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from openslide-python) (9.4.0)\n",
            "Building wheels for collected packages: openslide-python\n",
            "  Building wheel for openslide-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openslide-python: filename=openslide_python-1.3.1-cp310-cp310-linux_x86_64.whl size=33550 sha256=d5900dc185edc516ebdaed679b30243c6bea7a08373023013c79bbf73eabb1d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/79/fa/29a0087493c69dff7fd0b70fab5d6771002a531010161d2d97\n",
            "Successfully built openslide-python\n",
            "Installing collected packages: openslide-python\n",
            "Successfully installed openslide-python-1.3.1\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.1)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ],
      "source": [
        "%pip install torch\n",
        "%pip install torchvision\n",
        "%pip install h5py\n",
        "%pip install pandas\n",
        "%pip install PyYAML\n",
        "%pip install opencv-python\n",
        "%pip install matplotlib\n",
        "%pip install scikit-learn\n",
        "%pip install scipy\n",
        "%pip install tqdm\n",
        "%pip install openslide-python\n",
        "%pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43iH21pZJ4nn",
        "outputId": "c3c376de-b213-4f8d-b902-9fcf0ac432a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "v9lcImiyJ2IB",
        "outputId": "d67e6a7b-7b41-4a44-ffff-fa8555621667"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/oval-group/smooth-topk.git\n",
            "  Cloning https://github.com/oval-group/smooth-topk.git to /tmp/pip-req-build-brbqctvn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/oval-group/smooth-topk.git /tmp/pip-req-build-brbqctvn\n",
            "  Resolved https://github.com/oval-group/smooth-topk.git to commit 12c1645f187e2fa0c05f47bf1fe48864d4bd2707\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.10/dist-packages (from topk==1.0) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from topk==1.0) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->topk==1.0) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->topk==1.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->topk==1.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->topk==1.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->topk==1.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->topk==1.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->topk==1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->topk==1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->topk==1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->topk==1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->topk==1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->topk==1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->topk==1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->topk==1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->topk==1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->topk==1.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->topk==1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->topk==1.0) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0->topk==1.0) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0->topk==1.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0->topk==1.0) (1.3.0)\n",
            "Building wheels for collected packages: topk\n",
            "  Building wheel for topk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for topk: filename=topk-1.0-py3-none-any.whl size=9985 sha256=5072522e1935ee89bef5088f61bf8da802b9f147af552401e3eb6d294c7071df\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cdcur494/wheels/b5/e1/65/94fdd820e9a24c2f8520b542ddea5a1d05e88fb34fd768d536\n",
            "Successfully built topk\n",
            "Installing collected packages: topk\n",
            "Successfully installed topk-1.0\n"
          ]
        }
      ],
      "source": [
        "%pip install git+https://github.com/oval-group/smooth-topk.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6b4L9TzAK0Vp",
        "outputId": "8e502e8e-eee7-458e-fc88-c9ae19384399"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/Mahmoodlab/CONCH.git\n",
            "  Cloning https://github.com/Mahmoodlab/CONCH.git to /tmp/pip-req-build-ukn441p2\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Mahmoodlab/CONCH.git /tmp/pip-req-build-ukn441p2\n",
            "  Resolved https://github.com/Mahmoodlab/CONCH.git to commit f7bed1c32b4365feb2c65eb4231ae211ee19354f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from conch==0.1.0) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from conch==0.1.0) (0.18.1+cu121)\n",
            "Collecting transformers==4.31.0 (from conch==0.1.0)\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers<0.14,>=0.12.1 (from conch==0.1.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from conch==0.1.0) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from conch==0.1.0) (1.2.2)\n",
            "Requirement already satisfied: timm==0.9.8 in /usr/local/lib/python3.10/dist-packages (from conch==0.1.0) (0.9.8)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from conch==0.1.0) (2024.5.15)\n",
            "Collecting ftfy (from conch==0.1.0)\n",
            "  Downloading ftfy-6.2.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from conch==0.1.0) (3.9.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from conch==0.1.0) (2.0.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.8->conch==0.1.0) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.8->conch==0.1.0) (0.23.5)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.8->conch==0.1.0) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->conch==0.1.0) (3.15.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->conch==0.1.0) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->conch==0.1.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->conch==0.1.0) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->conch==0.1.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->conch==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->conch==0.1.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->conch==0.1.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->conch==0.1.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->conch==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->conch==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->conch==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->conch==0.1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->conch==0.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->conch==0.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->conch==0.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->conch==0.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->conch==0.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->conch==0.1.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->conch==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->conch==0.1.0) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.1->conch==0.1.0) (12.5.82)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->conch==0.1.0) (0.2.13)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->conch==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->conch==0.1.0) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->conch==0.1.0) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->conch==0.1.0) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->conch==0.1.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->conch==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->conch==0.1.0) (9.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->conch==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.1->conch==0.1.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->conch==0.1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->conch==0.1.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->conch==0.1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->conch==0.1.0) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.1->conch==0.1.0) (1.3.0)\n",
            "Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: conch\n",
            "  Building wheel for conch (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for conch: filename=conch-0.1.0-py3-none-any.whl size=413327 sha256=9aa0addb8e95929d3672131ce7f0af7ee4cbc661a925175c6a416005920d323a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wyqg2sns/wheels/0a/27/73/38d1a8400ebd14c51a6eb306f672fdabbcf789fa25f66723b3\n",
            "Successfully built conch\n",
            "Installing collected packages: tokenizers, ftfy, transformers, conch\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.42.4\n",
            "    Uninstalling transformers-4.42.4:\n",
            "      Successfully uninstalled transformers-4.42.4\n",
            "Successfully installed conch-0.1.0 ftfy-6.2.0 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ],
      "source": [
        "%pip install git+https://github.com/Mahmoodlab/CONCH.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "g8Nv0voVSdUp",
        "outputId": "130b7679-b42e-4795-ecac-829c9f80a48b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-07-25 08:40:55--  https://gdc.cancer.gov/files/public/file/gdc-client_v1.6.1_Ubuntu_x64.zip\n",
            "Resolving gdc.cancer.gov (gdc.cancer.gov)... 23.23.219.186, 34.193.29.102\n",
            "Connecting to gdc.cancer.gov (gdc.cancer.gov)|23.23.219.186|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://gdc.cancer.gov/system/files/public/file/gdc-client_v1.6.1_Ubuntu_x64.zip [following]\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2024-07-25 08:40:56--  https://gdc.cancer.gov/system/files/public/file/gdc-client_v1.6.1_Ubuntu_x64.zip\n",
            "Reusing existing connection to gdc.cancer.gov:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23940006 (23M) [application/zip]\n",
            "Saving to: ‘gdc-client.zip’\n",
            "\n",
            "gdc-client.zip      100%[===================>]  22.83M  15.2MB/s    in 1.5s    \n",
            "\n",
            "2024-07-25 08:40:58 (15.2 MB/s) - ‘gdc-client.zip’ saved [23940006/23940006]\n",
            "\n",
            "Archive:  gdc-client.zip\n",
            " extracting: gdc-client              \n"
          ]
        }
      ],
      "source": [
        "# Download the gdc-client binary\n",
        "!wget https://gdc.cancer.gov/files/public/file/gdc-client_v1.6.1_Ubuntu_x64.zip -O gdc-client.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "!unzip gdc-client.zip\n",
        "\n",
        "# Move the gdc-client binary to /usr/local/bin to make it executable from anywhere\n",
        "!chmod +x gdc-client\n",
        "!mv gdc-client /bin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiD3_eb3fTPd",
        "outputId": "f5cc2a59-9d6f-4f5e-fda4-8b143690a43f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "v1.6.1\n"
          ]
        }
      ],
      "source": [
        "# Check if gdc-client is correctly installed\n",
        "!gdc-client --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWJ-FX_K2gE7",
        "outputId": "63c3a121-60ab-4872-a360-c2629adb44d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "openslide-tools is already the newest version (3.4.1+dfsg-5build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Requirement already satisfied: openslide-python in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from openslide-python) (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y openslide-tools\n",
        "% openslide-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6BHeo-PpYbw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(\"/content/DATA_DIRECTORY\", exist_ok = True)\n",
        "os.makedirs(\"/content/CLAM/DATA_DIRECTORY\", exist_ok = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVJrUD9mAgs7",
        "outputId": "d461fd23-e747-43b0-b20d-69fc030597b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/DATA_DIRECTORY\n"
          ]
        }
      ],
      "source": [
        "cd /content/DATA_DIRECTORY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pXzHidB5i4Y"
      },
      "source": [
        "Download dataset using .txt file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rsa1zPq6nMwl",
        "outputId": "9df01fc5-e54e-4093-e68a-2ccbb59b8bcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% [#################################################################] Time:  0:00:34   7.6 MiB/s \n",
            "100% [#################################################################] Time:  0:00:45   8.1 MiB/s \n",
            "100% [#################################################################] Time:  0:00:15   5.3 MiB/s \n",
            "100% [#################################################################] Time:  0:00:39   8.4 MiB/s \n",
            "100% [#################################################################] Time:  0:00:55   8.7 MiB/s \n",
            "100% [#################################################################] Time:  0:00:44   7.5 MiB/s \n",
            "100% [#################################################################] Time:  0:00:26   8.3 MiB/s \n",
            "\u001b[32mSuccessfully downloaded\u001b[0m: 7\n"
          ]
        }
      ],
      "source": [
        "# download dataset using manifest file.\n",
        "# one can donwload manifest file from : https://portal.gdc.cancer.gov/analysis_page?app=Downloads\n",
        "!gdc-client download -m /content/gdc_manifest.2024-07-23.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du9bjXPvDT8d",
        "outputId": "a8e33eb6-bb0c-42e4-9cc7-56417e7502be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All .svs files have been moved to CLAM/DATA_DIRECTORY\n"
          ]
        }
      ],
      "source": [
        "# move all svs files at required location\n",
        "import openslide\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the source and destination directories\n",
        "data_directory = '/content/DATA_DIRECTORY'\n",
        "destination_directory = '/content/CLAM/DATA_DIRECTORY'\n",
        "\n",
        "# Walk through the directory structure\n",
        "for root, dirs, files in os.walk(data_directory):\n",
        "    for file in files:\n",
        "        if file.endswith('.svs'):\n",
        "            # Construct full file path\n",
        "            source_file = os.path.join(root, file)\n",
        "            # Move file to the destination directory\n",
        "            shutil.move(source_file, destination_directory)\n",
        "\n",
        "print(\"All .svs files have been moved to CLAM/DATA_DIRECTORY\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RYeYcVWA351",
        "outputId": "9d725079-b84c-47ae-9b80-5f41507e0e91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/CLAM\n"
          ]
        }
      ],
      "source": [
        "cd /content/CLAM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z_9S4TX6D78"
      },
      "source": [
        "Generate patches from WSIs with default parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KINWs2j--oE0",
        "outputId": "faa95a8b-a505-43af-83f7-06d7ef057805"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "source:  DATA_DIRECTORY\n",
            "patch_save_dir:  RESULTS_DIRECTORY/patches\n",
            "mask_save_dir:  RESULTS_DIRECTORY/masks\n",
            "stitch_save_dir:  RESULTS_DIRECTORY/stitches\n",
            "source : DATA_DIRECTORY\n",
            "save_dir : RESULTS_DIRECTORY\n",
            "patch_save_dir : RESULTS_DIRECTORY/patches\n",
            "mask_save_dir : RESULTS_DIRECTORY/masks\n",
            "stitch_save_dir : RESULTS_DIRECTORY/stitches\n",
            "{'seg_params': {'seg_level': -1, 'sthresh': 8, 'mthresh': 7, 'close': 4, 'use_otsu': False, 'keep_ids': 'none', 'exclude_ids': 'none'}, 'filter_params': {'a_t': 100, 'a_h': 16, 'max_n_holes': 8}, 'patch_params': {'use_padding': True, 'contour_fn': 'four_pt'}, 'vis_params': {'vis_level': -1, 'line_thickness': 250}}\n",
            "\r  0% 0/7 [00:00<?, ?it/s]\n",
            "\n",
            "progress: 0.00, 0/7\n",
            "processing TCGA-2G-AAFG-05A-01-TS1.BA326925-F3B6-441D-B5AE-4091825B3153.svs\n",
            "Creating patches for:  TCGA-2G-AAFG-05A-01-TS1.BA326925-F3B6-441D-B5AE-4091825B3153 ...\n",
            "Total number of contours to process:  2\n",
            "Bounding Box: 3200 6371 27720 17417\n",
            "Contour Area: 298152561.0\n",
            "Extracted 4642 coordinates\n",
            "Bounding Box: 70992 1568 28391 17994\n",
            "Contour Area: 328971158.0\n",
            "Extracted 5166 coordinates\n",
            "original size: 101591 x 26573\n",
            "downscaled size for stiching: 3174 x 830\n",
            "start stitching TCGA-2G-AAFG-05A-01-TS1.BA326925-F3B6-441D-B5AE-4091825B3153\n",
            "number of patches: 9808\n",
            "patch size: 256 x 256 patch level: 0\n",
            "ref patch size: (256, 256) x (256, 256)\n",
            "downscaled patch size: 8x8\n",
            "\n",
            "  0% 0/9808 [00:00<?, ?it/s]\u001b[A\n",
            " 12% 1172/9808 [00:00<00:00, 11713.53it/s]\u001b[A\n",
            " 24% 2377/9808 [00:00<00:00, 11907.86it/s]\u001b[A\n",
            " 36% 3572/9808 [00:00<00:00, 11926.09it/s]\u001b[A\n",
            " 49% 4785/9808 [00:00<00:00, 12003.32it/s]\u001b[A\n",
            " 61% 6001/9808 [00:00<00:00, 12050.51it/s]\u001b[A\n",
            " 74% 7249/9808 [00:00<00:00, 12193.10it/s]\u001b[A\n",
            " 87% 8503/9808 [00:00<00:00, 12305.68it/s]\u001b[A\n",
            "100% 9808/9808 [00:00<00:00, 11871.98it/s]\n",
            "segmentation took 0.33637499809265137 seconds\n",
            "patching took 0.5410723686218262 seconds\n",
            "stitching took 0.9114713668823242 seconds\n",
            " 14% 1/7 [00:01<00:11,  1.99s/it]\n",
            "\n",
            "progress: 0.14, 1/7\n",
            "processing TCGA-2G-AAGI-05A-01-TS1.348DECBB-5C9C-41D2-99DE-3DE6CA6302D7.svs\n",
            "Creating patches for:  TCGA-2G-AAGI-05A-01-TS1.348DECBB-5C9C-41D2-99DE-3DE6CA6302D7 ...\n",
            "Total number of contours to process:  2\n",
            "Bounding Box: 3904 5409 22053 21223\n",
            "Contour Area: 253567581.0\n",
            "Extracted 3972 coordinates\n",
            "Bounding Box: 57546 1312 22021 21287\n",
            "Contour Area: 250977644.0\n",
            "Extracted 3941 coordinates\n",
            "original size: 83663 x 29448\n",
            "downscaled size for stiching: 2614 x 920\n",
            "start stitching TCGA-2G-AAGI-05A-01-TS1.348DECBB-5C9C-41D2-99DE-3DE6CA6302D7\n",
            "number of patches: 7913\n",
            "patch size: 256 x 256 patch level: 0\n",
            "ref patch size: (256, 256) x (256, 256)\n",
            "downscaled patch size: 8x8\n",
            "\n",
            "  0% 0/7913 [00:00<?, ?it/s]\u001b[A\n",
            " 15% 1149/7913 [00:00<00:00, 11470.92it/s]\u001b[A\n",
            " 29% 2297/7913 [00:00<00:00, 11178.87it/s]\u001b[A\n",
            " 44% 3517/7913 [00:00<00:00, 11637.30it/s]\u001b[A\n",
            " 60% 4773/7913 [00:00<00:00, 11996.08it/s]\u001b[A\n",
            " 76% 6001/7913 [00:00<00:00, 12095.04it/s]\u001b[A\n",
            "100% 7913/7913 [00:00<00:00, 11895.62it/s]\n",
            "segmentation took 0.2041606903076172 seconds\n",
            "patching took 0.46733903884887695 seconds\n",
            "stitching took 0.7294249534606934 seconds\n",
            " 29% 2/7 [00:03<00:08,  1.72s/it]\n",
            "\n",
            "progress: 0.29, 2/7\n",
            "processing TCGA-2G-AAGY-05A-01-TS1.35E8F0A0-B248-476F-AE99-867F81B7AFA9.svs\n",
            "Creating patches for:  TCGA-2G-AAGY-05A-01-TS1.35E8F0A0-B248-476F-AE99-867F81B7AFA9 ...\n",
            "Total number of contours to process:  2\n",
            "Bounding Box: 58963 6403 34412 24333\n",
            "Contour Area: 423916261.0\n",
            "Extracted 6621 coordinates\n",
            "Bounding Box: 2976 2881 31692 26606\n",
            "Contour Area: 395401184.0\n",
            "Extracted 6167 coordinates\n",
            "original size: 95615 x 33873\n",
            "downscaled size for stiching: 2987 x 1058\n",
            "start stitching TCGA-2G-AAGY-05A-01-TS1.35E8F0A0-B248-476F-AE99-867F81B7AFA9\n",
            "number of patches: 12788\n",
            "patch size: 256 x 256 patch level: 0\n",
            "ref patch size: (256, 256) x (256, 256)\n",
            "downscaled patch size: 8x8\n",
            "\n",
            "  0% 0/12788 [00:00<?, ?it/s]\u001b[A\n",
            "  6% 772/12788 [00:00<00:01, 7716.68it/s]\u001b[A\n",
            " 12% 1544/12788 [00:00<00:01, 7617.19it/s]\u001b[A\n",
            " 18% 2359/12788 [00:00<00:01, 7856.55it/s]\u001b[A\n",
            " 25% 3171/12788 [00:00<00:01, 7956.41it/s]\u001b[A\n",
            " 31% 3967/12788 [00:00<00:01, 6928.85it/s]\u001b[A\n",
            " 37% 4766/12788 [00:00<00:01, 7256.09it/s]\u001b[A\n",
            " 44% 5573/12788 [00:00<00:00, 7503.47it/s]\u001b[A\n",
            " 50% 6425/12788 [00:00<00:00, 7811.09it/s]\u001b[A\n",
            " 56% 7216/12788 [00:00<00:00, 7332.84it/s]\u001b[A\n",
            " 62% 7961/12788 [00:01<00:00, 7067.97it/s]\u001b[A\n",
            " 68% 8677/12788 [00:01<00:00, 6820.70it/s]\u001b[A\n",
            " 73% 9373/12788 [00:01<00:00, 6858.14it/s]\u001b[A\n",
            " 79% 10166/12788 [00:01<00:00, 7162.28it/s]\u001b[A\n",
            " 85% 10888/12788 [00:01<00:00, 6896.65it/s]\u001b[A\n",
            " 91% 11583/12788 [00:01<00:00, 6909.59it/s]\u001b[A\n",
            "100% 12788/12788 [00:01<00:00, 7137.32it/s]\n",
            "segmentation took 0.29404568672180176 seconds\n",
            "patching took 0.9063572883605957 seconds\n",
            "stitching took 1.9324491024017334 seconds\n",
            " 43% 3/7 [00:06<00:09,  2.45s/it]\n",
            "\n",
            "progress: 0.43, 3/7\n",
            "processing TCGA-2G-AAHP-05A-01-TS1.8E9CC707-7E53-4480-BB13-03035AE3823E.svs\n",
            "Creating patches for:  TCGA-2G-AAHP-05A-01-TS1.8E9CC707-7E53-4480-BB13-03035AE3823E ...\n",
            "Total number of contours to process:  2\n",
            "Bounding Box: 86193 6178 28999 26350\n",
            "Contour Area: 455134844.0\n",
            "Extracted 7064 coordinates\n",
            "Bounding Box: 4064 3521 29607 26702\n",
            "Contour Area: 466732973.0\n",
            "Extracted 7250 coordinates\n",
            "original size: 117528 x 33904\n",
            "downscaled size for stiching: 3672 x 1059\n",
            "start stitching TCGA-2G-AAHP-05A-01-TS1.8E9CC707-7E53-4480-BB13-03035AE3823E\n",
            "number of patches: 14314\n",
            "patch size: 256 x 256 patch level: 0\n",
            "ref patch size: (256, 256) x (256, 256)\n",
            "downscaled patch size: 8x8\n",
            "\n",
            "  0% 0/14314 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 1200/14314 [00:00<00:01, 11990.46it/s]\u001b[A\n",
            " 17% 2438/14314 [00:00<00:00, 12218.35it/s]\u001b[A\n",
            " 26% 3660/14314 [00:00<00:00, 12115.50it/s]\u001b[A\n",
            " 34% 4885/14314 [00:00<00:00, 12166.40it/s]\u001b[A\n",
            " 43% 6102/14314 [00:00<00:00, 12000.41it/s]\u001b[A\n",
            " 51% 7303/14314 [00:00<00:00, 11900.00it/s]\u001b[A\n",
            " 59% 8494/14314 [00:00<00:00, 11406.11it/s]\u001b[A\n",
            " 68% 9662/14314 [00:00<00:00, 11487.05it/s]\u001b[A\n",
            " 76% 10870/14314 [00:00<00:00, 11666.16it/s]\u001b[A\n",
            " 84% 12088/14314 [00:01<00:00, 11820.86it/s]\u001b[A\n",
            "100% 14314/14314 [00:01<00:00, 11913.68it/s]\n",
            "segmentation took 0.5545315742492676 seconds\n",
            "patching took 0.816460371017456 seconds\n",
            "stitching took 1.306823968887329 seconds\n",
            " 57% 4/7 [00:09<00:07,  2.63s/it]\n",
            "\n",
            "progress: 0.57, 4/7\n",
            "processing TCGA-2G-AAKG-05A-01-TS1.4EA5A324-61E1-4AA7-BB44-4BF35A1C5E1D.svs\n",
            "Creating patches for:  TCGA-2G-AAKG-05A-01-TS1.4EA5A324-61E1-4AA7-BB44-4BF35A1C5E1D ...\n",
            "Total number of contours to process:  2\n",
            "Bounding Box: 2912 10179 30022 22665\n",
            "Contour Area: 407895722.0\n",
            "Extracted 6376 coordinates\n",
            "Bounding Box: 65194 3745 31526 22057\n",
            "Contour Area: 421244232.0\n",
            "Extracted 6567 coordinates\n",
            "original size: 99600 x 34188\n",
            "downscaled size for stiching: 3112 x 1068\n",
            "start stitching TCGA-2G-AAKG-05A-01-TS1.4EA5A324-61E1-4AA7-BB44-4BF35A1C5E1D\n",
            "number of patches: 12943\n",
            "patch size: 256 x 256 patch level: 0\n",
            "ref patch size: (256, 256) x (256, 256)\n",
            "downscaled patch size: 8x8\n",
            "\n",
            "  0% 0/12943 [00:00<?, ?it/s]\u001b[A\n",
            "  9% 1200/12943 [00:00<00:00, 11992.69it/s]\u001b[A\n",
            " 19% 2405/12943 [00:00<00:00, 12018.80it/s]\u001b[A\n",
            " 28% 3607/12943 [00:00<00:00, 11005.24it/s]\u001b[A\n",
            " 36% 4717/12943 [00:00<00:00, 10961.31it/s]\u001b[A\n",
            " 45% 5864/12943 [00:00<00:00, 11136.61it/s]\u001b[A\n",
            " 54% 7041/12943 [00:00<00:00, 11343.66it/s]\u001b[A\n",
            " 63% 8179/12943 [00:00<00:00, 11273.64it/s]\u001b[A\n",
            " 73% 9425/12943 [00:00<00:00, 11642.37it/s]\u001b[A\n",
            " 82% 10610/12943 [00:00<00:00, 11705.00it/s]\u001b[A\n",
            "100% 12943/12943 [00:01<00:00, 11560.83it/s]\n",
            "segmentation took 0.2814164161682129 seconds\n",
            "patching took 0.7444226741790771 seconds\n",
            "stitching took 1.222428560256958 seconds\n",
            " 71% 5/7 [00:12<00:05,  2.56s/it]\n",
            "\n",
            "progress: 0.71, 5/7\n",
            "processing TCGA-2G-AAKG-05A-02-TS2.F4EEB935-40A1-4F15-A44A-84F8749C406C.svs\n",
            "Creating patches for:  TCGA-2G-AAKG-05A-02-TS2.F4EEB935-40A1-4F15-A44A-84F8749C406C ...\n",
            "Total number of contours to process:  3\n",
            "Bounding Box: 74694 39247 7585 8036\n",
            "Contour Area: 29212288.0\n",
            "Extracted 489 coordinates\n",
            "Bounding Box: 59364 9315 37700 30925\n",
            "Contour Area: 630223587.0\n",
            "Extracted 9821 coordinates\n",
            "Bounding Box: 3200 3553 33860 30317\n",
            "Contour Area: 546782752.0\n",
            "Extracted 8508 coordinates\n",
            "original size: 97608 x 48659\n",
            "downscaled size for stiching: 3050 x 1520\n",
            "start stitching TCGA-2G-AAKG-05A-02-TS2.F4EEB935-40A1-4F15-A44A-84F8749C406C\n",
            "number of patches: 18818\n",
            "patch size: 256 x 256 patch level: 0\n",
            "ref patch size: (256, 256) x (256, 256)\n",
            "downscaled patch size: 8x8\n",
            "\n",
            "  0% 0/18818 [00:00<?, ?it/s]\u001b[A\n",
            "  6% 1223/18818 [00:00<00:01, 12225.06it/s]\u001b[A\n",
            " 13% 2446/18818 [00:00<00:01, 11581.85it/s]\u001b[A\n",
            " 20% 3672/18818 [00:00<00:01, 11881.91it/s]\u001b[A\n",
            " 26% 4909/18818 [00:00<00:01, 12070.35it/s]\u001b[A\n",
            " 33% 6118/18818 [00:00<00:01, 12067.30it/s]\u001b[A\n",
            " 39% 7326/18818 [00:00<00:00, 12006.67it/s]\u001b[A\n",
            " 46% 8571/18818 [00:00<00:00, 12147.56it/s]\u001b[A\n",
            " 52% 9833/18818 [00:00<00:00, 12293.57it/s]\u001b[A\n",
            " 59% 11063/18818 [00:00<00:00, 12241.47it/s]\u001b[A\n",
            " 65% 12288/18818 [00:01<00:00, 12044.69it/s]\u001b[A\n",
            " 72% 13539/18818 [00:01<00:00, 12182.45it/s]\u001b[A\n",
            " 78% 14759/18818 [00:01<00:00, 11792.98it/s]\u001b[A\n",
            " 85% 15994/18818 [00:01<00:00, 11954.70it/s]\u001b[A\n",
            " 92% 17219/18818 [00:01<00:00, 12039.33it/s]\u001b[A\n",
            "100% 18818/18818 [00:01<00:00, 12018.16it/s]\n",
            "segmentation took 0.372652530670166 seconds\n",
            "patching took 1.2461299896240234 seconds\n",
            "stitching took 1.7382111549377441 seconds\n",
            " 86% 6/7 [00:15<00:02,  2.92s/it]\n",
            "\n",
            "progress: 0.86, 6/7\n",
            "processing TCGA-2G-AAKO-05A-01-TS1.CFE3C35A-4658-448B-9393-321C9702181F.svs\n",
            "Creating patches for:  TCGA-2G-AAKO-05A-01-TS1.CFE3C35A-4658-448B-9393-321C9702181F ...\n",
            "Total number of contours to process:  2\n",
            "Bounding Box: 62725 4391 19587 8654\n",
            "Contour Area: 79364367.0\n",
            "Extracted 1268 coordinates\n",
            "Bounding Box: 9792 4294 15747 6540\n",
            "Contour Area: 48142411.0\n",
            "Extracted 794 coordinates\n",
            "original size: 89640 x 14391\n",
            "downscaled size for stiching: 2801 x 449\n",
            "start stitching TCGA-2G-AAKO-05A-01-TS1.CFE3C35A-4658-448B-9393-321C9702181F\n",
            "number of patches: 2062\n",
            "patch size: 256 x 256 patch level: 0\n",
            "ref patch size: (256, 256) x (256, 256)\n",
            "downscaled patch size: 8x8\n",
            "\n",
            "  0% 0/2062 [00:00<?, ?it/s]\u001b[A\n",
            "100% 2062/2062 [00:00<00:00, 12088.77it/s]\n",
            "segmentation took 0.09651613235473633 seconds\n",
            "patching took 0.20473957061767578 seconds\n",
            "stitching took 0.19294142723083496 seconds\n",
            "100% 7/7 [00:16<00:00,  2.34s/it]\n",
            "average segmentation time in s per slide: 0.305671146937779\n",
            "average patching time in s per slide: 0.7037887573242188\n",
            "average stiching time in s per slide: 1.1476786477225167\n"
          ]
        }
      ],
      "source": [
        "!python create_patches_fp.py --source DATA_DIRECTORY --save_dir RESULTS_DIRECTORY --patch_size 256 --seg --patch --stitch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6UlcTRf6N1V"
      },
      "source": [
        "Generate patches from WSIs with from parameters in csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YQSFofcDGiF9",
        "outputId": "665668a2-5c67-4f18-ea0d-9c3f937fc1f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "source:  DATA_DIRECTORY\n",
            "patch_save_dir:  RESULTS_DIRECTORY/patches\n",
            "mask_save_dir:  RESULTS_DIRECTORY/masks\n",
            "stitch_save_dir:  RESULTS_DIRECTORY/stitches\n",
            "source : DATA_DIRECTORY\n",
            "save_dir : RESULTS_DIRECTORY\n",
            "patch_save_dir : RESULTS_DIRECTORY/patches\n",
            "mask_save_dir : RESULTS_DIRECTORY/masks\n",
            "stitch_save_dir : RESULTS_DIRECTORY/stitches\n",
            "{'seg_params': {'seg_level': -1, 'sthresh': 15, 'mthresh': 11, 'close': 2, 'use_otsu': False, 'keep_ids': 'none', 'exclude_ids': 'none'}, 'filter_params': {'a_t': 1, 'a_h': 1, 'max_n_holes': 2}, 'patch_params': {'use_padding': True, 'contour_fn': 'four_pt'}, 'vis_params': {'vis_level': -1, 'line_thickness': 50}}\n",
            "\r  0% 0/7 [00:00<?, ?it/s]\n",
            "\n",
            "progress: 0.00, 0/7\n",
            "processing TCGA-2G-AAFG-05A-01-TS1.BA326925-F3B6-441D-B5AE-4091825B3153.svs\n",
            "TCGA-2G-AAFG-05A-01-TS1.BA326925-F3B6-441D-B5AE-4091825B3153 already exist in destination location, skipped\n",
            "\n",
            "\n",
            "progress: 0.14, 1/7\n",
            "processing TCGA-2G-AAGI-05A-01-TS1.348DECBB-5C9C-41D2-99DE-3DE6CA6302D7.svs\n",
            "TCGA-2G-AAGI-05A-01-TS1.348DECBB-5C9C-41D2-99DE-3DE6CA6302D7 already exist in destination location, skipped\n",
            "\n",
            "\n",
            "progress: 0.29, 2/7\n",
            "processing TCGA-2G-AAGY-05A-01-TS1.35E8F0A0-B248-476F-AE99-867F81B7AFA9.svs\n",
            "TCGA-2G-AAGY-05A-01-TS1.35E8F0A0-B248-476F-AE99-867F81B7AFA9 already exist in destination location, skipped\n",
            "\n",
            "\n",
            "progress: 0.43, 3/7\n",
            "processing TCGA-2G-AAHP-05A-01-TS1.8E9CC707-7E53-4480-BB13-03035AE3823E.svs\n",
            "TCGA-2G-AAHP-05A-01-TS1.8E9CC707-7E53-4480-BB13-03035AE3823E already exist in destination location, skipped\n",
            "\n",
            "\n",
            "progress: 0.57, 4/7\n",
            "processing TCGA-2G-AAKG-05A-01-TS1.4EA5A324-61E1-4AA7-BB44-4BF35A1C5E1D.svs\n",
            "TCGA-2G-AAKG-05A-01-TS1.4EA5A324-61E1-4AA7-BB44-4BF35A1C5E1D already exist in destination location, skipped\n",
            "\n",
            "\n",
            "progress: 0.71, 5/7\n",
            "processing TCGA-2G-AAKG-05A-02-TS2.F4EEB935-40A1-4F15-A44A-84F8749C406C.svs\n",
            "TCGA-2G-AAKG-05A-02-TS2.F4EEB935-40A1-4F15-A44A-84F8749C406C already exist in destination location, skipped\n",
            "\n",
            "\n",
            "progress: 0.86, 6/7\n",
            "processing TCGA-2G-AAKO-05A-01-TS1.CFE3C35A-4658-448B-9393-321C9702181F.svs\n",
            "TCGA-2G-AAKO-05A-01-TS1.CFE3C35A-4658-448B-9393-321C9702181F already exist in destination location, skipped\n",
            "\r100% 7/7 [00:00<00:00, 760.01it/s]\n",
            "average segmentation time in s per slide: 0.0\n",
            "average patching time in s per slide: 0.0\n",
            "average stiching time in s per slide: 0.0\n"
          ]
        }
      ],
      "source": [
        "!python create_patches_fp.py --source DATA_DIRECTORY --save_dir RESULTS_DIRECTORY --patch_size 256 --preset bwh_biopsy.csv --seg --patch --stitch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "k-D0VmooGp4P",
        "outputId": "3e73c63c-d13a-4948-a6c3-f08e020640a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "source:  DATA_DIRECTORY\n",
            "patch_save_dir:  RESULTS_DIRECTORY/patches\n",
            "mask_save_dir:  RESULTS_DIRECTORY/masks\n",
            "stitch_save_dir:  RESULTS_DIRECTORY/stitches\n",
            "source : DATA_DIRECTORY\n",
            "save_dir : RESULTS_DIRECTORY\n",
            "patch_save_dir : RESULTS_DIRECTORY/patches\n",
            "mask_save_dir : RESULTS_DIRECTORY/masks\n",
            "stitch_save_dir : RESULTS_DIRECTORY/stitches\n",
            "{'seg_params': {'seg_level': -1, 'sthresh': 8, 'mthresh': 7, 'close': 4, 'use_otsu': False, 'keep_ids': 'none', 'exclude_ids': 'none'}, 'filter_params': {'a_t': 100, 'a_h': 16, 'max_n_holes': 8}, 'patch_params': {'use_padding': True, 'contour_fn': 'four_pt'}, 'vis_params': {'vis_level': -1, 'line_thickness': 250}}\n",
            "\r  0% 0/2 [00:00<?, ?it/s]\n",
            "\n",
            "progress: 0.00, 0/2\n",
            "processing TCGA-2G-AAGI-05Z-00-DX1.5D660578-C22C-49F5-A680-348AD0DFE7E6.svs\n",
            "TCGA-2G-AAGI-05Z-00-DX1.5D660578-C22C-49F5-A680-348AD0DFE7E6 already exist in destination location, skipped\n",
            "\n",
            "\n",
            "progress: 0.50, 1/2\n",
            "processing TCGA-2G-AAHP-05Z-00-DX2.372858CD-846F-497B-AD9B-E38851B453CC.svs\n",
            "TCGA-2G-AAHP-05Z-00-DX2.372858CD-846F-497B-AD9B-E38851B453CC already exist in destination location, skipped\n",
            "\r100% 2/2 [00:00<00:00, 499.65it/s]\n",
            "average segmentation time in s per slide: 0.0\n",
            "average patching time in s per slide: 0.0\n",
            "average stiching time in s per slide: 0.0\n"
          ]
        }
      ],
      "source": [
        "!python create_patches_fp.py --source DATA_DIRECTORY --save_dir RESULTS_DIRECTORY --patch_size 256 --seg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVErz98c6WKc"
      },
      "source": [
        "Feature extrection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nDEnJqmIFqAg",
        "outputId": "7b324931-0257-4b5a-9e4b-3351a0818b5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initializing dataset\n",
            "loading model checkpoint\n",
            "model.safetensors: 100% 102M/102M [00:03<00:00, 30.1MB/s]\n",
            "TimmCNNEncoder(\n",
            "  (model): FeatureListNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (act1): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pool): AdaptiveAvgPool2d(output_size=1)\n",
            ")\n",
            "  0% 0/7 [00:00<?, ?it/s]\n",
            "progress: 0/7\n",
            "TCGA-2G-AAFG-05A-01-TS1.BA326925-F3B6-441D-B5AE-4091825B3153\n",
            "downsample [1. 1.]\n",
            "downsampled_level_dim [101591  26573]\n",
            "level_dim [101591  26573]\n",
            "name TCGA-2G-AAFG-05A-01-TS1.BA326925-F3B6-441D-B5AE-4091825B3153\n",
            "patch_level 0\n",
            "patch_size 256\n",
            "save_path RESULTS_DIRECTORY/patches\n",
            "\n",
            "feature extraction settings\n",
            "transformations:  Compose(\n",
            "    Resize(size=224, interpolation=bilinear, max_size=None, antialias=True)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "processing a total of 20 batches\n",
            "\n",
            "  0% 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 1/20 [00:52<16:38, 52.56s/it]\u001b[A\n",
            " 10% 2/20 [00:53<06:44, 22.46s/it]\u001b[A\n",
            " 15% 3/20 [00:55<03:36, 12.75s/it]\u001b[A\n",
            " 20% 4/20 [00:56<02:14,  8.42s/it]\u001b[A\n",
            " 25% 5/20 [00:58<01:27,  5.80s/it]\u001b[A\n",
            " 30% 6/20 [00:59<00:59,  4.22s/it]\u001b[A\n",
            " 35% 7/20 [01:00<00:42,  3.24s/it]\u001b[A\n",
            " 40% 8/20 [01:01<00:30,  2.57s/it]\u001b[A\n",
            " 45% 9/20 [01:05<00:34,  3.12s/it]\u001b[A\n",
            " 50% 10/20 [01:07<00:25,  2.50s/it]\u001b[A\n",
            " 55% 11/20 [01:08<00:18,  2.11s/it]\u001b[A\n",
            " 60% 12/20 [01:09<00:14,  1.83s/it]\u001b[A\n",
            " 65% 13/20 [01:10<00:11,  1.63s/it]\u001b[A\n",
            " 70% 14/20 [01:11<00:09,  1.50s/it]\u001b[A\n",
            " 75% 15/20 [01:12<00:06,  1.39s/it]\u001b[A\n",
            " 80% 16/20 [01:14<00:05,  1.32s/it]\u001b[A\n",
            " 85% 17/20 [01:20<00:08,  2.72s/it]\u001b[A\n",
            " 90% 18/20 [01:21<00:04,  2.24s/it]\u001b[A\n",
            " 95% 19/20 [01:22<00:01,  1.90s/it]\u001b[A\n",
            "100% 20/20 [01:22<00:00,  4.14s/it]\n",
            "\n",
            "computing features for FEATURES_DIRECTORY/h5_files/TCGA-2G-AAFG-05A-01-TS1.BA326925-F3B6-441D-B5AE-4091825B3153.h5 took 82.85468006134033 s\n",
            "features size:  (9808, 1024)\n",
            "coordinates size:  (9808, 2)\n",
            " 14% 1/7 [01:23<08:18, 83.00s/it]\n",
            "progress: 1/7\n",
            "TCGA-2G-AAGI-05A-01-TS1.348DECBB-5C9C-41D2-99DE-3DE6CA6302D7\n",
            "downsample [1. 1.]\n",
            "downsampled_level_dim [83663 29448]\n",
            "level_dim [83663 29448]\n",
            "name TCGA-2G-AAGI-05A-01-TS1.348DECBB-5C9C-41D2-99DE-3DE6CA6302D7\n",
            "patch_level 0\n",
            "patch_size 256\n",
            "save_path RESULTS_DIRECTORY/patches\n",
            "\n",
            "feature extraction settings\n",
            "transformations:  Compose(\n",
            "    Resize(size=224, interpolation=bilinear, max_size=None, antialias=True)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")\n",
            "processing a total of 16 batches\n",
            "\n",
            "  0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "  6% 1/16 [00:26<06:35, 26.34s/it]\u001b[A\n",
            " 12% 2/16 [00:29<02:59, 12.83s/it]\u001b[A\n",
            " 19% 3/16 [00:30<01:37,  7.51s/it]\u001b[A\n",
            " 25% 4/16 [00:32<01:02,  5.22s/it]\u001b[A\n",
            " 31% 5/16 [00:33<00:41,  3.80s/it]\u001b[A\n",
            " 38% 6/16 [00:35<00:29,  2.95s/it]\u001b[A\n",
            " 44% 7/16 [00:36<00:21,  2.37s/it]\u001b[A\n",
            " 50% 8/16 [00:37<00:15,  1.99s/it]\u001b[A\n",
            " 56% 9/16 [00:51<00:39,  5.68s/it]\u001b[A\n",
            " 62% 10/16 [00:52<00:26,  4.40s/it]\u001b[A\n",
            " 69% 11/16 [00:54<00:17,  3.40s/it]\u001b[A\n",
            " 75% 12/16 [00:55<00:10,  2.71s/it]\u001b[A\n",
            " 81% 13/16 [00:56<00:06,  2.23s/it]\u001b[A\n",
            " 88% 14/16 [00:57<00:03,  1.90s/it]\u001b[A\n",
            " 94% 15/16 [00:58<00:01,  1.67s/it]\u001b[A\n",
            "100% 16/16 [00:59<00:00,  3.72s/it]\n",
            "\n",
            "computing features for FEATURES_DIRECTORY/h5_files/TCGA-2G-AAGI-05A-01-TS1.348DECBB-5C9C-41D2-99DE-3DE6CA6302D7.h5 took 59.61081910133362 s\n",
            "features size:  (7913, 1024)\n",
            "coordinates size:  (7913, 2)\n",
            " 29% 2/7 [02:22<05:46, 69.39s/it]\n",
            "progress: 2/7\n",
            "TCGA-2G-AAGY-05A-01-TS1.35E8F0A0-B248-476F-AE99-867F81B7AFA9\n",
            "downsample [1. 1.]\n",
            "downsampled_level_dim [95615 33873]\n",
            "level_dim [95615 33873]\n",
            "name TCGA-2G-AAGY-05A-01-TS1.35E8F0A0-B248-476F-AE99-867F81B7AFA9\n",
            "patch_level 0\n",
            "patch_size 256\n",
            "save_path RESULTS_DIRECTORY/patches\n",
            "\n",
            "feature extraction settings\n",
            "transformations:  Compose(\n",
            "    Resize(size=224, interpolation=bilinear, max_size=None, antialias=True)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")\n",
            "processing a total of 25 batches\n",
            "\n",
            "  0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/25 [00:46<18:38, 46.62s/it]\u001b[A\n",
            "  8% 2/25 [00:47<07:37, 19.90s/it]\u001b[A\n",
            " 12% 3/25 [00:49<04:09, 11.36s/it]\u001b[A\n",
            " 16% 4/25 [00:50<02:34,  7.34s/it]\u001b[A\n",
            " 20% 5/25 [00:51<01:42,  5.13s/it]\u001b[A\n",
            " 24% 6/25 [00:52<01:11,  3.79s/it]\u001b[A\n",
            " 28% 7/25 [00:53<00:52,  2.94s/it]\u001b[A\n",
            " 32% 8/25 [00:54<00:40,  2.37s/it]\u001b[A\n",
            " 36% 9/25 [01:15<02:09,  8.07s/it]\u001b[A\n",
            " 40% 10/25 [01:16<01:28,  5.93s/it]\u001b[A\n",
            " 44% 11/25 [01:17<01:02,  4.48s/it]\u001b[A\n",
            " 48% 12/25 [01:19<00:45,  3.47s/it]\u001b[A\n",
            " 52% 13/25 [01:20<00:33,  2.78s/it]\u001b[A\n",
            " 56% 14/25 [01:21<00:25,  2.30s/it]\u001b[A\n",
            " 60% 15/25 [01:22<00:19,  1.97s/it]\u001b[A\n",
            " 64% 16/25 [01:23<00:15,  1.73s/it]\u001b[A\n",
            " 68% 17/25 [01:34<00:35,  4.48s/it]\u001b[A\n",
            " 72% 18/25 [01:35<00:24,  3.48s/it]\u001b[A\n",
            " 76% 19/25 [01:36<00:16,  2.78s/it]\u001b[A\n",
            " 80% 20/25 [01:38<00:11,  2.29s/it]\u001b[A\n",
            " 84% 21/25 [01:39<00:07,  1.95s/it]\u001b[A\n",
            " 88% 22/25 [01:40<00:05,  1.71s/it]\u001b[A\n",
            " 92% 23/25 [01:41<00:03,  1.55s/it]\u001b[A\n",
            " 96% 24/25 [01:42<00:01,  1.43s/it]\u001b[A\n",
            "100% 25/25 [01:44<00:00,  4.17s/it]\n",
            "\n",
            "computing features for FEATURES_DIRECTORY/h5_files/TCGA-2G-AAGY-05A-01-TS1.35E8F0A0-B248-476F-AE99-867F81B7AFA9.h5 took 104.2813172340393 s\n",
            "features size:  (12788, 1024)\n",
            "coordinates size:  (12788, 2)\n",
            " 43% 3/7 [04:07<05:41, 85.43s/it]\n",
            "progress: 3/7\n",
            "TCGA-2G-AAHP-05A-01-TS1.8E9CC707-7E53-4480-BB13-03035AE3823E\n",
            "downsample [1. 1.]\n",
            "downsampled_level_dim [117528  33904]\n",
            "level_dim [117528  33904]\n",
            "name TCGA-2G-AAHP-05A-01-TS1.8E9CC707-7E53-4480-BB13-03035AE3823E\n",
            "patch_level 0\n",
            "patch_size 256\n",
            "save_path RESULTS_DIRECTORY/patches\n",
            "\n",
            "feature extraction settings\n",
            "transformations:  Compose(\n",
            "    Resize(size=224, interpolation=bilinear, max_size=None, antialias=True)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")\n",
            "processing a total of 28 batches\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:25<11:34, 25.73s/it]\u001b[A\n",
            "  7% 2/28 [00:31<06:07, 14.12s/it]\u001b[A\n",
            " 11% 3/28 [00:32<03:26,  8.25s/it]\u001b[A\n",
            " 14% 4/28 [00:34<02:12,  5.53s/it]\u001b[A\n",
            " 18% 5/28 [00:35<01:31,  4.00s/it]\u001b[A\n",
            " 21% 6/28 [00:36<01:06,  3.04s/it]\u001b[A\n",
            " 25% 7/28 [00:38<00:51,  2.44s/it]\u001b[A\n",
            " 29% 8/28 [00:39<00:40,  2.04s/it]\u001b[A\n",
            " 32% 9/28 [00:55<02:04,  6.58s/it]\u001b[A\n",
            " 36% 10/28 [00:58<01:37,  5.42s/it]\u001b[A\n",
            " 39% 11/28 [01:05<01:38,  5.77s/it]\u001b[A\n",
            " 43% 12/28 [01:06<01:10,  4.40s/it]\u001b[A\n",
            " 46% 13/28 [01:07<00:51,  3.42s/it]\u001b[A\n",
            " 50% 14/28 [01:08<00:38,  2.75s/it]\u001b[A\n",
            " 54% 15/28 [01:09<00:29,  2.28s/it]\u001b[A\n",
            " 57% 16/28 [01:11<00:23,  1.96s/it]\u001b[A\n",
            " 61% 17/28 [01:28<01:10,  6.44s/it]\u001b[A\n",
            " 64% 18/28 [01:30<00:51,  5.12s/it]\u001b[A\n",
            " 68% 19/28 [01:32<00:40,  4.45s/it]\u001b[A\n",
            " 71% 20/28 [01:34<00:27,  3.47s/it]\u001b[A\n",
            " 75% 21/28 [01:35<00:19,  2.79s/it]\u001b[A\n",
            " 79% 22/28 [01:36<00:13,  2.30s/it]\u001b[A\n",
            " 82% 23/28 [01:37<00:09,  1.96s/it]\u001b[A\n",
            " 86% 24/28 [01:38<00:06,  1.73s/it]\u001b[A\n",
            " 89% 25/28 [01:43<00:08,  2.69s/it]\u001b[A\n",
            " 93% 26/28 [01:44<00:04,  2.23s/it]\u001b[A\n",
            " 96% 27/28 [01:46<00:01,  1.91s/it]\u001b[A\n",
            "100% 28/28 [01:47<00:00,  3.84s/it]\n",
            "\n",
            "computing features for FEATURES_DIRECTORY/h5_files/TCGA-2G-AAHP-05A-01-TS1.8E9CC707-7E53-4480-BB13-03035AE3823E.h5 took 107.71182942390442 s\n",
            "features size:  (14314, 1024)\n",
            "coordinates size:  (14314, 2)\n",
            " 57% 4/7 [05:55<04:42, 94.28s/it]\n",
            "progress: 4/7\n",
            "TCGA-2G-AAKG-05A-01-TS1.4EA5A324-61E1-4AA7-BB44-4BF35A1C5E1D\n",
            "downsample [1. 1.]\n",
            "downsampled_level_dim [99600 34188]\n",
            "level_dim [99600 34188]\n",
            "name TCGA-2G-AAKG-05A-01-TS1.4EA5A324-61E1-4AA7-BB44-4BF35A1C5E1D\n",
            "patch_level 0\n",
            "patch_size 256\n",
            "save_path RESULTS_DIRECTORY/patches\n",
            "\n",
            "feature extraction settings\n",
            "transformations:  Compose(\n",
            "    Resize(size=224, interpolation=bilinear, max_size=None, antialias=True)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")\n",
            "processing a total of 26 batches\n",
            "\n",
            "  0% 0/26 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/26 [00:29<12:26, 29.87s/it]\u001b[A\n",
            "  8% 2/26 [00:31<05:12, 13.04s/it]\u001b[A\n",
            " 12% 3/26 [00:32<02:56,  7.69s/it]\u001b[A\n",
            " 15% 4/26 [00:33<01:52,  5.13s/it]\u001b[A\n",
            " 19% 5/26 [00:34<01:17,  3.71s/it]\u001b[A\n",
            " 23% 6/26 [00:36<00:57,  2.86s/it]\u001b[A\n",
            " 27% 7/26 [00:38<00:49,  2.59s/it]\u001b[A\n",
            " 31% 8/26 [00:39<00:38,  2.16s/it]\u001b[A\n",
            " 35% 9/26 [01:01<02:21,  8.33s/it]\u001b[A\n",
            " 38% 10/26 [01:02<01:38,  6.13s/it]\u001b[A\n",
            " 42% 11/26 [01:03<01:09,  4.62s/it]\u001b[A\n",
            " 46% 12/26 [01:04<00:50,  3.57s/it]\u001b[A\n",
            " 50% 13/26 [01:06<00:37,  2.88s/it]\u001b[A\n",
            " 54% 14/26 [01:07<00:28,  2.40s/it]\u001b[A\n",
            " 58% 15/26 [01:08<00:22,  2.05s/it]\u001b[A\n",
            " 62% 16/26 [01:09<00:18,  1.83s/it]\u001b[A\n",
            " 65% 17/26 [01:28<01:02,  6.90s/it]\u001b[A\n",
            " 69% 18/26 [01:29<00:41,  5.19s/it]\u001b[A\n",
            " 73% 19/26 [01:31<00:27,  4.00s/it]\u001b[A\n",
            " 77% 20/26 [01:32<00:18,  3.15s/it]\u001b[A\n",
            " 81% 21/26 [01:33<00:12,  2.56s/it]\u001b[A\n",
            " 85% 22/26 [01:34<00:08,  2.14s/it]\u001b[A\n",
            " 88% 23/26 [01:35<00:05,  1.84s/it]\u001b[A\n",
            " 92% 24/26 [01:36<00:03,  1.64s/it]\u001b[A\n",
            " 96% 25/26 [01:38<00:01,  1.57s/it]\u001b[A\n",
            "100% 26/26 [01:38<00:00,  3.81s/it]\n",
            "\n",
            "computing features for FEATURES_DIRECTORY/h5_files/TCGA-2G-AAKG-05A-01-TS1.4EA5A324-61E1-4AA7-BB44-4BF35A1C5E1D.h5 took 98.9840943813324 s\n",
            "features size:  (12943, 1024)\n",
            "coordinates size:  (12943, 2)\n",
            " 71% 5/7 [07:34<03:12, 96.02s/it]\n",
            "progress: 5/7\n",
            "TCGA-2G-AAKG-05A-02-TS2.F4EEB935-40A1-4F15-A44A-84F8749C406C\n",
            "downsample [1. 1.]\n",
            "downsampled_level_dim [97608 48659]\n",
            "level_dim [97608 48659]\n",
            "name TCGA-2G-AAKG-05A-02-TS2.F4EEB935-40A1-4F15-A44A-84F8749C406C\n",
            "patch_level 0\n",
            "patch_size 256\n",
            "save_path RESULTS_DIRECTORY/patches\n",
            "\n",
            "feature extraction settings\n",
            "transformations:  Compose(\n",
            "    Resize(size=224, interpolation=bilinear, max_size=None, antialias=True)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")\n",
            "processing a total of 37 batches\n",
            "\n",
            "  0% 0/37 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 1/37 [00:28<17:05, 28.49s/it]\u001b[A\n",
            "  5% 2/37 [00:29<07:17, 12.51s/it]\u001b[A\n",
            "  8% 3/37 [00:31<04:11,  7.39s/it]\u001b[A\n",
            " 11% 4/37 [00:33<03:00,  5.48s/it]\u001b[A\n",
            " 14% 5/37 [00:35<02:14,  4.20s/it]\u001b[A\n",
            " 16% 6/37 [00:36<01:38,  3.17s/it]\u001b[A\n",
            " 19% 7/37 [00:37<01:15,  2.53s/it]\u001b[A\n",
            " 22% 8/37 [00:39<01:01,  2.11s/it]\u001b[A\n",
            " 24% 9/37 [00:54<02:58,  6.38s/it]\u001b[A\n",
            " 27% 10/37 [00:56<02:09,  4.78s/it]\u001b[A\n",
            " 30% 11/37 [00:59<01:51,  4.27s/it]\u001b[A\n",
            " 32% 12/37 [01:00<01:23,  3.36s/it]\u001b[A\n",
            " 35% 13/37 [01:05<01:30,  3.79s/it]\u001b[A\n",
            " 38% 14/37 [01:06<01:09,  3.00s/it]\u001b[A\n",
            " 41% 15/37 [01:07<00:54,  2.46s/it]\u001b[A\n",
            " 43% 16/37 [01:08<00:43,  2.08s/it]\u001b[A\n",
            " 46% 17/37 [01:24<02:04,  6.21s/it]\u001b[A\n",
            " 49% 18/37 [01:26<01:33,  4.90s/it]\u001b[A\n",
            " 51% 19/37 [01:28<01:09,  3.87s/it]\u001b[A\n",
            " 54% 20/37 [01:34<01:17,  4.59s/it]\u001b[A\n",
            " 57% 21/37 [01:35<00:57,  3.57s/it]\u001b[A\n",
            " 59% 22/37 [01:36<00:42,  2.85s/it]\u001b[A\n",
            " 62% 23/37 [01:37<00:33,  2.36s/it]\u001b[A\n",
            " 65% 24/37 [01:39<00:26,  2.00s/it]\u001b[A\n",
            " 68% 25/37 [01:55<01:15,  6.30s/it]\u001b[A\n",
            " 70% 26/37 [01:57<00:57,  5.20s/it]\u001b[A\n",
            " 73% 27/37 [01:59<00:40,  4.02s/it]\u001b[A\n",
            " 76% 28/37 [02:00<00:28,  3.17s/it]\u001b[A\n",
            " 78% 29/37 [02:01<00:21,  2.67s/it]\u001b[A\n",
            " 81% 30/37 [02:03<00:15,  2.23s/it]\u001b[A\n",
            " 84% 31/37 [02:04<00:11,  1.92s/it]\u001b[A\n",
            " 86% 32/37 [02:05<00:08,  1.70s/it]\u001b[A\n",
            " 89% 33/37 [02:14<00:14,  3.73s/it]\u001b[A\n",
            " 92% 34/37 [02:15<00:08,  2.96s/it]\u001b[A\n",
            " 95% 35/37 [02:16<00:04,  2.42s/it]\u001b[A\n",
            " 97% 36/37 [02:17<00:02,  2.04s/it]\u001b[A\n",
            "100% 37/37 [02:18<00:00,  3.76s/it]\n",
            "\n",
            "computing features for FEATURES_DIRECTORY/h5_files/TCGA-2G-AAKG-05A-02-TS2.F4EEB935-40A1-4F15-A44A-84F8749C406C.h5 took 139.0544626712799 s\n",
            "features size:  (18818, 1024)\n",
            "coordinates size:  (18818, 2)\n",
            " 86% 6/7 [09:53<01:50, 110.79s/it]\n",
            "progress: 6/7\n",
            "TCGA-2G-AAKO-05A-01-TS1.CFE3C35A-4658-448B-9393-321C9702181F\n",
            "downsample [1. 1.]\n",
            "downsampled_level_dim [89640 14391]\n",
            "level_dim [89640 14391]\n",
            "name TCGA-2G-AAKO-05A-01-TS1.CFE3C35A-4658-448B-9393-321C9702181F\n",
            "patch_level 0\n",
            "patch_size 256\n",
            "save_path RESULTS_DIRECTORY/patches\n",
            "\n",
            "feature extraction settings\n",
            "transformations:  Compose(\n",
            "    Resize(size=224, interpolation=bilinear, max_size=None, antialias=True)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")\n",
            "processing a total of 5 batches\n",
            "\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20% 1/5 [00:14<00:56, 14.08s/it]\u001b[A\n",
            " 40% 2/5 [00:15<00:19,  6.50s/it]\u001b[A\n",
            " 60% 3/5 [00:16<00:08,  4.07s/it]\u001b[A\n",
            " 80% 4/5 [00:17<00:02,  2.93s/it]\u001b[A\n",
            "100% 5/5 [00:18<00:00,  3.68s/it]\n",
            "\n",
            "computing features for FEATURES_DIRECTORY/h5_files/TCGA-2G-AAKO-05A-01-TS1.CFE3C35A-4658-448B-9393-321C9702181F.h5 took 18.4435453414917 s\n",
            "features size:  (2062, 1024)\n",
            "coordinates size:  (2062, 2)\n",
            "100% 7/7 [10:12<00:00, 87.49s/it]\n"
          ]
        }
      ],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python extract_features_fp.py --data_h5_dir \"/content/CLAM/RESULTS_DIRECTORY\" --data_slide_dir DATA_DIRECTORY --csv_path \"/content/CLAM/RESULTS_DIRECTORY/process_list_autogen.csv\" --feat_dir FEATURES_DIRECTORY --batch_size 512 --slide_ext .svs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "19b3bfde14d842fc9764a97ffd66b7c5",
            "374954057414425cbf0c2be9d7fead21",
            "a1b709a111794270b5c876a8931ab567",
            "04732da1f3fb42f297fa1c6216552b17",
            "49ceba181f11481eb98c2e5dcf69ee51",
            "1ff7b7323be0431bae569584f0926391",
            "418f1ea87da843d3a1db7d8e76606f6b",
            "bf38c04244e3420aac46eb951de7c46f",
            "c9f3264a4aa645609da709e2762f291f",
            "53b162fcd3ea496cac2930b6f52da71c",
            "bb3172b0324747388c3457cb658c4710",
            "76c9349cae63425e8eb6ee4ba54bdd05",
            "ed69754570e44424a62cdc2726fccdca",
            "8413ab14f84840738138a648f9fa604a",
            "97d2eada0ffb4d5d9ebb16799ddc60f2",
            "9bc5f1af9e5b4d618c81477f793d66a8",
            "429304bb15f74a5d9675d88e5a6d540d",
            "ac85b4e3835e4e8a9d6dbb4f1d15cb60",
            "c2ab21bdef484efc8e96696b47842be5",
            "30e92883186343b58176f489ac146298",
            "246643b1249f4b7a9341e958a394a464",
            "ce30efab66c34b488067a25900fa3bc9",
            "c1ca130f4b204a0ba37af3e2cc9bee61",
            "b0fcda53b4bb4c15975a126e7c1f11ab",
            "bdf9b880ff5c4d05a151b6990acc23a9",
            "b68d3637e39141f380e6af67f5a9fc6d",
            "834fe0656cf64ef493da227b87e42c63",
            "4141dce74a2f41ee914000447e20c521",
            "37912621793b418eabd754daf14a4553",
            "a26a6962fc5b4c2e852778cd68190549",
            "3333f41853a649a5b71df87c8cb6b6d0",
            "e16caedc58d74ab6aa4abe6f9471f4b1",
            "83e393b5a08d446cb08872a733acfc86",
            "9a499bc57df94439affebade6d3bd22f",
            "6449580c5ea34f2e96a40ce745648494",
            "2608fe3a82d748baa06feccb930e2749",
            "b483aa232832487bbde5cb454f8aa6d7",
            "05d2a5c046d04708a2872dc0f39eb6c7",
            "d8fb710672d2458789c7c2d1a9d60038",
            "18ddab8bc4dc4f8fbba630eb9cefe3d0",
            "79f34794e0dd41e89223443b551d87b2",
            "e90bd251600f4ef7ac5a77dbe48584b0",
            "4df74e5a5eda484391cfd792132a0955"
          ]
        },
        "collapsed": true,
        "id": "x_I9hhTLPC9H",
        "outputId": "2fd22da7-305a-458c-8b04-f3c50f5cf46e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19b3bfde14d842fc9764a97ffd66b7c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac85b4e3835e4e8a9d6dbb4f1d15cb60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.21G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "VisionTransformer(\n",
              "  (patch_embed): PatchEmbed(\n",
              "    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
              "    (norm): Identity()\n",
              "  )\n",
              "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "  (patch_drop): Identity()\n",
              "  (norm_pre): Identity()\n",
              "  (blocks): Sequential(\n",
              "    (0): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (1): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (2): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (3): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (4): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (5): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (6): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (7): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (8): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (9): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (10): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (11): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (12): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (13): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (14): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (15): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (16): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (17): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (18): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (19): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (20): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (21): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (22): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "    (23): Block(\n",
              "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls1): LayerScale()\n",
              "      (drop_path1): Identity()\n",
              "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (drop1): Dropout(p=0.0, inplace=False)\n",
              "        (norm): Identity()\n",
              "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (drop2): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ls2): LayerScale()\n",
              "      (drop_path2): Identity()\n",
              "    )\n",
              "  )\n",
              "  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "  (fc_norm): Identity()\n",
              "  (head_drop): Dropout(p=0.0, inplace=False)\n",
              "  (head): Identity()\n",
              ")"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!cd /content/\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import timm\n",
        "from huggingface_hub import login, hf_hub_download\n",
        "\n",
        "login()  # login with your User Access Token, found at https://huggingface.co/settings/tokens\n",
        "\n",
        "local_dir = \"../assets/ckpts/vit_large_patch16_224.dinov2.uni_mass100k/\"\n",
        "os.makedirs(local_dir, exist_ok=True)  # create directory if it does not exist\n",
        "hf_hub_download(\"MahmoodLab/UNI\", filename=\"pytorch_model.bin\", local_dir=local_dir, force_download=True)\n",
        "model = timm.create_model(\n",
        "    \"vit_large_patch16_224\", img_size=224, patch_size=16, init_values=1e-5, num_classes=0, dynamic_img_size=True\n",
        ")\n",
        "model.load_state_dict(torch.load(os.path.join(local_dir, \"pytorch_model.bin\"), map_location=\"cpu\"), strict=True)\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ]\n",
        ")\n",
        "model.eval()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C20HSjc9F-GA"
      },
      "outputs": [],
      "source": [
        "# pre trained encoder\n",
        "!export CONCH_CKPT_PATH=/content/assets/ckpts/vit_large_patch16_224.dinov2.uni_mass100k/pytorch_model.bin\n",
        "#!export UNI_CKPT_PATH=checkpoints/uni/pytorch_model.bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1nUd1RZ_HhD",
        "outputId": "b1152515-05f4-45ca-b304-4ae56430b09d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/CLAM\n"
          ]
        }
      ],
      "source": [
        "cd /content/CLAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oVaX8FZxJze",
        "outputId": "16170319-16d7-49c5-c83e-d197a69df549"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duplicating h5_files...\n",
            "Created TCGA-2G-AAKO-05A-01-TS1(1).CFE3C35A-4658-448B-9393-321C9702181F(1).h5 from TCGA-2G-AAKO-05A-01-TS1.CFE3C35A-4658-448B-9393-321C9702181F.h5\n",
            "Created TCGA-2G-AAFG-05A-01-TS1(1).BA326925-F3B6-441D-B5AE-4091825B3153(1).h5 from TCGA-2G-AAFG-05A-01-TS1.BA326925-F3B6-441D-B5AE-4091825B3153.h5\n",
            "Created TCGA-2G-AAGI-05A-01-TS1(1).348DECBB-5C9C-41D2-99DE-3DE6CA6302D7(1).h5 from TCGA-2G-AAGI-05A-01-TS1.348DECBB-5C9C-41D2-99DE-3DE6CA6302D7.h5\n",
            "Created TCGA-2G-AAHP-05A-01-TS1(1).8E9CC707-7E53-4480-BB13-03035AE3823E(1).h5 from TCGA-2G-AAHP-05A-01-TS1.8E9CC707-7E53-4480-BB13-03035AE3823E.h5\n",
            "Created TCGA-2G-AAGY-05A-01-TS1(1).35E8F0A0-B248-476F-AE99-867F81B7AFA9(1).h5 from TCGA-2G-AAGY-05A-01-TS1.35E8F0A0-B248-476F-AE99-867F81B7AFA9.h5\n",
            "Created TCGA-2G-AAKG-05A-01-TS1(1).4EA5A324-61E1-4AA7-BB44-4BF35A1C5E1D(1).h5 from TCGA-2G-AAKG-05A-01-TS1.4EA5A324-61E1-4AA7-BB44-4BF35A1C5E1D.h5\n",
            "Created TCGA-2G-AAKG-05A-02-TS2(1).F4EEB935-40A1-4F15-A44A-84F8749C406C(1).h5 from TCGA-2G-AAKG-05A-02-TS2.F4EEB935-40A1-4F15-A44A-84F8749C406C.h5\n",
            "Duplicating pt_files...\n",
            "Created TCGA-2G-AAFG-05A-01-TS1(1).BA326925-F3B6-441D-B5AE-4091825B3153(1).pt from TCGA-2G-AAFG-05A-01-TS1.BA326925-F3B6-441D-B5AE-4091825B3153.pt\n",
            "Created TCGA-2G-AAHP-05A-01-TS1(1).8E9CC707-7E53-4480-BB13-03035AE3823E(1).pt from TCGA-2G-AAHP-05A-01-TS1.8E9CC707-7E53-4480-BB13-03035AE3823E.pt\n",
            "Created TCGA-2G-AAKG-05A-02-TS2(1).F4EEB935-40A1-4F15-A44A-84F8749C406C(1).pt from TCGA-2G-AAKG-05A-02-TS2.F4EEB935-40A1-4F15-A44A-84F8749C406C.pt\n",
            "Created TCGA-2G-AAGI-05A-01-TS1(1).348DECBB-5C9C-41D2-99DE-3DE6CA6302D7(1).pt from TCGA-2G-AAGI-05A-01-TS1.348DECBB-5C9C-41D2-99DE-3DE6CA6302D7.pt\n",
            "Created TCGA-2G-AAKG-05A-01-TS1(1).4EA5A324-61E1-4AA7-BB44-4BF35A1C5E1D(1).pt from TCGA-2G-AAKG-05A-01-TS1.4EA5A324-61E1-4AA7-BB44-4BF35A1C5E1D.pt\n",
            "Created TCGA-2G-AAKO-05A-01-TS1(1).CFE3C35A-4658-448B-9393-321C9702181F(1).pt from TCGA-2G-AAKO-05A-01-TS1.CFE3C35A-4658-448B-9393-321C9702181F.pt\n",
            "Created TCGA-2G-AAGY-05A-01-TS1(1).35E8F0A0-B248-476F-AE99-867F81B7AFA9(1).pt from TCGA-2G-AAGY-05A-01-TS1.35E8F0A0-B248-476F-AE99-867F81B7AFA9.pt\n",
            "Duplication process completed.\n"
          ]
        }
      ],
      "source": [
        "# create dummy data\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Function to duplicate files in a directory\n",
        "def duplicate_files(directory, file_extension, file_dir):\n",
        "    # Iterate over the files in the specified directory\n",
        "    for filename in os.listdir(os.path.join(directory, file_dir)):\n",
        "        if filename.endswith('.' + file_extension):\n",
        "            original_file = os.path.join(directory, file_dir, filename)\n",
        "            new_filename = filename.replace('.', '(1).')\n",
        "            duplicated_file = os.path.join(directory, file_dir, new_filename)\n",
        "\n",
        "            # Copy the file with a new name\n",
        "            shutil.copyfile(original_file, duplicated_file)\n",
        "            print(f\"Created {new_filename} from {filename}\")\n",
        "\n",
        "# Example usage\n",
        "\n",
        "base_dir = '/content/CLAM/FEATURES_DIRECTORY'\n",
        "file_extensions = ['h5', 'pt']\n",
        "file_dir = ['h5_files', 'pt_files']\n",
        "for ext, dir in zip(file_extensions,file_dir):\n",
        "    print(f\"Duplicating {ext}_files...\")\n",
        "    duplicate_files(base_dir, ext, dir)\n",
        "\n",
        "print(\"Duplication process completed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNrvklPtHlDV",
        "outputId": "72f9f92d-e852-4ea0-bd5b-2b9460889b7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label column: label\n",
            "label dictionary: {'normal_tissue': 0, 'tumor_tissue': 1}\n",
            "number of classes: 2\n",
            "slide-level counts:  \n",
            " label\n",
            "1     4\n",
            "0    10\n",
            "Name: count, dtype: int64\n",
            "Patient-LVL; Number of samples registered in class 0: 5\n",
            "Slide-LVL; Number of samples registered in class 0: 10\n",
            "Patient-LVL; Number of samples registered in class 1: 4\n",
            "Slide-LVL; Number of samples registered in class 1: 4\n",
            "\n",
            "number of training samples: 5\n",
            "number of samples in cls 0: 3\n",
            "number of samples in cls 1: 2\n",
            "\n",
            "number of val samples: 3\n",
            "number of samples in cls 0: 2\n",
            "number of samples in cls 1: 1\n",
            "\n",
            "number of test samples: 4\n",
            "number of samples in cls 0: 3\n",
            "number of samples in cls 1: 1\n",
            "\n",
            "\n",
            "\n",
            "number of training samples: 7\n",
            "number of samples in cls 0: 5\n",
            "number of samples in cls 1: 2\n",
            "\n",
            "number of val samples: 3\n",
            "number of samples in cls 0: 2\n",
            "number of samples in cls 1: 1\n",
            "\n",
            "number of test samples: 3\n",
            "number of samples in cls 0: 2\n",
            "number of samples in cls 1: 1\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python create_splits_seq.py --task task_1_tumor_vs_normal --seed 1 --k 2 --label_frac 0.6 --val_frac 0.2 --test_frac 0.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5Txc2lZJ7sC"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"/content/CLAM/DATA_ROOT_DIR\", exist_ok= True)\n",
        "#os.makedirs(\"/content/CLAM/DATA_ROOT_DIR/tumor_vs_normal_resnet_features\", exist_ok= True)\n",
        "os.rename(\"/content/CLAM/FEATURES_DIRECTORY\", \"/content/CLAM/tumor_vs_normal_resnet_features\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVyDt71HAeoB",
        "outputId": "78c6d5e3-23b4-464e-9e99-6ae975ef440c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Load Dataset\n",
            "label column: label\n",
            "label dictionary: {'normal_tissue': 0, 'tumor_tissue': 1}\n",
            "number of classes: 2\n",
            "slide-level counts:  \n",
            " label\n",
            "1     4\n",
            "0    10\n",
            "Name: count, dtype: int64\n",
            "Patient-LVL; Number of samples registered in class 0: 5\n",
            "Slide-LVL; Number of samples registered in class 0: 10\n",
            "Patient-LVL; Number of samples registered in class 1: 4\n",
            "Slide-LVL; Number of samples registered in class 1: 4\n",
            "split_dir:  splits/task_1_tumor_vs_normal_60\n",
            "################# Settings ###################\n",
            "num_splits:  2\n",
            "k_start:  -1\n",
            "k_end:  -1\n",
            "task:  task_1_tumor_vs_normal\n",
            "max_epochs:  200\n",
            "results_dir:  ./results\n",
            "lr:  0.0002\n",
            "experiment:  task_1_tumor_vs_normal\n",
            "reg:  1e-05\n",
            "label_frac:  0.6\n",
            "bag_loss:  ce\n",
            "seed:  1\n",
            "model_type:  clam_sb\n",
            "model_size:  small\n",
            "use_drop_out:  0.25\n",
            "weighted_sample:  False\n",
            "opt:  adam\n",
            "bag_weight:  0.7\n",
            "inst_loss:  svm\n",
            "B:  8\n",
            "split_dir:  splits/task_1_tumor_vs_normal_60\n",
            "\n",
            "Training Fold 0!\n",
            "\n",
            "Init train/val/test splits... \n",
            "Done!\n",
            "Training on 5 samples\n",
            "Validating on 3 samples\n",
            "Testing on 4 samples\n",
            "\n",
            "Init loss function... Done!\n",
            "\n",
            "Init Model... Setting tau to 1.0\n",
            "Done!\n",
            "CLAM_SB(\n",
            "  (attention_net): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.25, inplace=False)\n",
            "    (3): Attn_Net_Gated(\n",
            "      (attention_a): Sequential(\n",
            "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "        (1): Tanh()\n",
            "        (2): Dropout(p=0.25, inplace=False)\n",
            "      )\n",
            "      (attention_b): Sequential(\n",
            "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "        (1): Sigmoid()\n",
            "        (2): Dropout(p=0.25, inplace=False)\n",
            "      )\n",
            "      (attention_c): Linear(in_features=256, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (classifiers): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (instance_classifiers): ModuleList(\n",
            "    (0-1): 2 x Linear(in_features=512, out_features=2, bias=True)\n",
            "  )\n",
            "  (instance_loss_fn): SmoothTop1SVM()\n",
            ")\n",
            "Total number of parameters: 790791\n",
            "Total number of trainable parameters: 790791\n",
            "\n",
            "Init optimizer ... Done!\n",
            "\n",
            "Init Loaders.../usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            " Done!\n",
            "\n",
            "Setup EarlyStopping... Done!\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.4: correct 16/40\n",
            "class 1 clustering acc 0.6: correct 24/40\n",
            "Epoch: 0, train_loss: 0.7149, train_clustering_loss:  1.3135, train_error: 0.6000\n",
            "class 0: acc 0.0, correct 0/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.7068, val_error: 0.6667, auc: 0.5000\n",
            "class 0 clustering acc 0.3333333333333333: correct 8/24\n",
            "class 1 clustering acc 0.6666666666666666: correct 16/24\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "Validation loss decreased (inf --> 0.706765).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.425: correct 17/40\n",
            "class 1 clustering acc 0.6: correct 24/40\n",
            "Epoch: 1, train_loss: 0.6967, train_clustering_loss:  1.3127, train_error: 0.6000\n",
            "class 0: acc 0.0, correct 0/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.6932, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 0.3333333333333333: correct 8/24\n",
            "class 1 clustering acc 0.6666666666666666: correct 16/24\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "Validation loss decreased (0.706765 --> 0.693178).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.55: correct 22/40\n",
            "class 1 clustering acc 0.6: correct 24/40\n",
            "Epoch: 2, train_loss: 0.6872, train_clustering_loss:  1.3124, train_error: 0.6000\n",
            "class 0: acc 0.6666666666666666, correct 2/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6816, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 0.3333333333333333: correct 8/24\n",
            "class 1 clustering acc 0.6666666666666666: correct 16/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.693178 --> 0.681615).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.5: correct 20/40\n",
            "class 1 clustering acc 0.575: correct 23/40\n",
            "Epoch: 3, train_loss: 0.6950, train_clustering_loss:  1.3082, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6655, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 0.3333333333333333: correct 8/24\n",
            "class 1 clustering acc 0.6666666666666666: correct 16/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.681615 --> 0.665491).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.525: correct 21/40\n",
            "class 1 clustering acc 0.6: correct 24/40\n",
            "Epoch: 4, train_loss: 0.6764, train_clustering_loss:  1.2973, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6593, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 0.3333333333333333: correct 8/24\n",
            "class 1 clustering acc 0.6666666666666666: correct 16/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.665491 --> 0.659289).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.6: correct 24/40\n",
            "class 1 clustering acc 0.625: correct 25/40\n",
            "Epoch: 5, train_loss: 0.6739, train_clustering_loss:  1.2879, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6537, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 0.375: correct 9/24\n",
            "class 1 clustering acc 0.6666666666666666: correct 16/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.659289 --> 0.653660).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.775: correct 31/40\n",
            "class 1 clustering acc 0.6: correct 24/40\n",
            "Epoch: 6, train_loss: 0.6691, train_clustering_loss:  1.2627, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6542, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 0.875: correct 21/24\n",
            "class 1 clustering acc 0.6666666666666666: correct 16/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.95: correct 38/40\n",
            "class 1 clustering acc 0.825: correct 33/40\n",
            "Epoch: 7, train_loss: 0.6674, train_clustering_loss:  1.2396, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6535, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.653660 --> 0.653475).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.975: correct 39/40\n",
            "class 1 clustering acc 0.875: correct 35/40\n",
            "Epoch: 8, train_loss: 0.6654, train_clustering_loss:  1.2198, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6509, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.653475 --> 0.650925).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 0.975: correct 39/40\n",
            "Epoch: 9, train_loss: 0.6640, train_clustering_loss:  1.1887, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6487, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.650925 --> 0.648675).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 10, train_loss: 0.6645, train_clustering_loss:  1.1608, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6456, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.648675 --> 0.645557).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 11, train_loss: 0.6630, train_clustering_loss:  1.1286, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6434, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.645557 --> 0.643359).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 12, train_loss: 0.6634, train_clustering_loss:  1.0907, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6404, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.643359 --> 0.640407).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 13, train_loss: 0.6625, train_clustering_loss:  1.0499, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6427, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 14, train_loss: 0.6593, train_clustering_loss:  1.0122, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6405, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 15, train_loss: 0.6577, train_clustering_loss:  0.9702, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6412, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 16, train_loss: 0.6555, train_clustering_loss:  0.9251, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6403, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.640407 --> 0.640320).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 17, train_loss: 0.6568, train_clustering_loss:  0.8847, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6373, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.640320 --> 0.637308).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 18, train_loss: 0.6549, train_clustering_loss:  0.8377, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6398, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 19, train_loss: 0.6492, train_clustering_loss:  0.7887, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6387, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 20, train_loss: 0.6532, train_clustering_loss:  0.7487, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6410, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 21, train_loss: 0.6491, train_clustering_loss:  0.6958, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6350, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.637308 --> 0.634956).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 22, train_loss: 0.6387, train_clustering_loss:  0.6439, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6339, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.634956 --> 0.633889).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 23, train_loss: 0.6424, train_clustering_loss:  0.5996, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6297, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.633889 --> 0.629671).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 24, train_loss: 0.6257, train_clustering_loss:  0.5536, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6293, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.629671 --> 0.629307).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 25, train_loss: 0.6179, train_clustering_loss:  0.5171, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6289, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.629307 --> 0.628941).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 26, train_loss: 0.6122, train_clustering_loss:  0.4830, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6311, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 27, train_loss: 0.6050, train_clustering_loss:  0.4529, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6343, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 28, train_loss: 0.5880, train_clustering_loss:  0.4101, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6287, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.628941 --> 0.628734).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 29, train_loss: 0.5759, train_clustering_loss:  0.3792, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6278, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.628734 --> 0.627776).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 30, train_loss: 0.5593, train_clustering_loss:  0.3684, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6245, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.627776 --> 0.624485).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 31, train_loss: 0.5476, train_clustering_loss:  0.3232, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6211, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.624485 --> 0.621060).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 32, train_loss: 0.5276, train_clustering_loss:  0.3115, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6221, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 33, train_loss: 0.5108, train_clustering_loss:  0.3001, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6211, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.621060 --> 0.621058).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 34, train_loss: 0.4987, train_clustering_loss:  0.3073, train_error: 0.4000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6359, val_error: 0.6667, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 35, train_loss: 0.4773, train_clustering_loss:  0.3030, train_error: 0.2000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.5, correct 1/2\n",
            "\n",
            "Val Set, val_loss: 0.6547, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 36, train_loss: 0.4508, train_clustering_loss:  0.2995, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.6667, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 37, train_loss: 0.3887, train_clustering_loss:  0.2922, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.6546, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "EarlyStopping counter: 4 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 38, train_loss: 0.3886, train_clustering_loss:  0.2898, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.6361, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "EarlyStopping counter: 5 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 39, train_loss: 0.3766, train_clustering_loss:  0.3026, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.6528, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "EarlyStopping counter: 6 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 40, train_loss: 0.3258, train_clustering_loss:  0.3001, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.7045, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 0.875: correct 21/24\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "EarlyStopping counter: 7 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 41, train_loss: 0.2700, train_clustering_loss:  0.3095, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.7058, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 0.875: correct 21/24\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "EarlyStopping counter: 8 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 42, train_loss: 0.2447, train_clustering_loss:  0.3146, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.7242, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 0.7916666666666666: correct 19/24\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "EarlyStopping counter: 9 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 43, train_loss: 0.2038, train_clustering_loss:  0.3410, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.7921, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 0.6666666666666666: correct 16/24\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "EarlyStopping counter: 10 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 44, train_loss: 0.1933, train_clustering_loss:  0.3765, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.9252, val_error: 0.6667, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 0.6666666666666666: correct 16/24\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "EarlyStopping counter: 11 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 45, train_loss: 0.2022, train_clustering_loss:  0.3904, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.8084, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 0.6666666666666666: correct 16/24\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "EarlyStopping counter: 12 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 46, train_loss: 0.1412, train_clustering_loss:  0.3638, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.7604, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 0.6666666666666666: correct 16/24\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "EarlyStopping counter: 13 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 1.0: correct 40/40\n",
            "Epoch: 47, train_loss: 0.1292, train_clustering_loss:  0.3224, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.7541, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 0.6666666666666666: correct 16/24\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "EarlyStopping counter: 14 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 0.975: correct 39/40\n",
            "Epoch: 48, train_loss: 0.1527, train_clustering_loss:  0.3671, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.8873, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 0.6666666666666666: correct 16/24\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "EarlyStopping counter: 15 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 0.825: correct 33/40\n",
            "Epoch: 49, train_loss: 0.0968, train_clustering_loss:  0.6617, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.2084, val_error: 0.6667, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 0.5833333333333334: correct 14/24\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "EarlyStopping counter: 16 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 0.725: correct 29/40\n",
            "Epoch: 50, train_loss: 0.1074, train_clustering_loss:  0.8717, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.3581, val_error: 0.6667, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 0.4583333333333333: correct 11/24\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "EarlyStopping counter: 17 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 0.75: correct 30/40\n",
            "Epoch: 51, train_loss: 0.1053, train_clustering_loss:  0.8565, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.2109, val_error: 0.6667, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 0.5833333333333334: correct 14/24\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "EarlyStopping counter: 18 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 40/40\n",
            "class 1 clustering acc 0.8: correct 32/40\n",
            "Epoch: 52, train_loss: 0.0841, train_clustering_loss:  0.7269, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.0836, val_error: 0.6667, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 0.625: correct 15/24\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "EarlyStopping counter: 19 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.975: correct 39/40\n",
            "class 1 clustering acc 0.85: correct 34/40\n",
            "Epoch: 53, train_loss: 0.0724, train_clustering_loss:  0.6226, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.0121, val_error: 0.3333, auc: 0.5000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 0.625: correct 15/24\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 1.0, correct 1/1\n",
            "EarlyStopping counter: 20 out of 20\n",
            "Early stopping\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Val error: 0.3333, ROC AUC: 0.5000\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Test error: 0.2500, ROC AUC: 1.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/1\n",
            "\n",
            "Training Fold 1!\n",
            "\n",
            "Init train/val/test splits... \n",
            "Done!\n",
            "Training on 7 samples\n",
            "Validating on 3 samples\n",
            "Testing on 3 samples\n",
            "\n",
            "Init loss function... Done!\n",
            "\n",
            "Init Model... Setting tau to 1.0\n",
            "Done!\n",
            "CLAM_SB(\n",
            "  (attention_net): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.25, inplace=False)\n",
            "    (3): Attn_Net_Gated(\n",
            "      (attention_a): Sequential(\n",
            "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "        (1): Tanh()\n",
            "        (2): Dropout(p=0.25, inplace=False)\n",
            "      )\n",
            "      (attention_b): Sequential(\n",
            "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "        (1): Sigmoid()\n",
            "        (2): Dropout(p=0.25, inplace=False)\n",
            "      )\n",
            "      (attention_c): Linear(in_features=256, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (classifiers): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (instance_classifiers): ModuleList(\n",
            "    (0-1): 2 x Linear(in_features=512, out_features=2, bias=True)\n",
            "  )\n",
            "  (instance_loss_fn): SmoothTop1SVM()\n",
            ")\n",
            "Total number of parameters: 790791\n",
            "Total number of trainable parameters: 790791\n",
            "\n",
            "Init optimizer ... Done!\n",
            "\n",
            "Init Loaders.../usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            " Done!\n",
            "\n",
            "Setup EarlyStopping... Done!\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.2857142857142857: correct 16/56\n",
            "class 1 clustering acc 0.7142857142857143: correct 40/56\n",
            "Epoch: 0, train_loss: 0.6881, train_clustering_loss:  1.3118, train_error: 0.4286\n",
            "class 0: acc 0.8, correct 4/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6696, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 0.3333333333333333: correct 8/24\n",
            "class 1 clustering acc 0.6666666666666666: correct 16/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (inf --> 0.669629).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.30357142857142855: correct 17/56\n",
            "class 1 clustering acc 0.7142857142857143: correct 40/56\n",
            "Epoch: 1, train_loss: 0.6509, train_clustering_loss:  1.3009, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6507, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 0.3333333333333333: correct 8/24\n",
            "class 1 clustering acc 0.6666666666666666: correct 16/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.669629 --> 0.650731).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.5178571428571429: correct 29/56\n",
            "class 1 clustering acc 0.7142857142857143: correct 40/56\n",
            "Epoch: 2, train_loss: 0.6272, train_clustering_loss:  1.2873, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6365, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 0.75: correct 18/24\n",
            "class 1 clustering acc 0.6666666666666666: correct 16/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.650731 --> 0.636463).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.5535714285714286: correct 31/56\n",
            "class 1 clustering acc 0.7142857142857143: correct 40/56\n",
            "Epoch: 3, train_loss: 0.6238, train_clustering_loss:  1.2684, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6273, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 0.6666666666666666: correct 16/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.636463 --> 0.627327).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.8035714285714286: correct 45/56\n",
            "class 1 clustering acc 0.75: correct 42/56\n",
            "Epoch: 4, train_loss: 0.5996, train_clustering_loss:  1.2286, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6258, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 0.7083333333333334: correct 17/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.627327 --> 0.625762).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9285714285714286: correct 52/56\n",
            "class 1 clustering acc 0.8392857142857143: correct 47/56\n",
            "Epoch: 5, train_loss: 0.5975, train_clustering_loss:  1.1862, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6255, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.625762 --> 0.625465).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9642857142857143: correct 54/56\n",
            "class 1 clustering acc 0.9821428571428571: correct 55/56\n",
            "Epoch: 6, train_loss: 0.5942, train_clustering_loss:  1.1266, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6258, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9821428571428571: correct 55/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 7, train_loss: 0.5951, train_clustering_loss:  1.0769, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6272, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9642857142857143: correct 54/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 8, train_loss: 0.5922, train_clustering_loss:  1.0067, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6251, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.625465 --> 0.625128).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 9, train_loss: 0.5982, train_clustering_loss:  0.9480, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6288, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 10, train_loss: 0.6011, train_clustering_loss:  0.8777, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6240, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.625128 --> 0.623964).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 11, train_loss: 0.5879, train_clustering_loss:  0.8073, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6242, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 12, train_loss: 0.5945, train_clustering_loss:  0.7410, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6218, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.623964 --> 0.621754).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 13, train_loss: 0.5881, train_clustering_loss:  0.6769, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6225, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 14, train_loss: 0.5898, train_clustering_loss:  0.6189, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6240, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 15, train_loss: 0.5844, train_clustering_loss:  0.5627, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6220, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 16, train_loss: 0.5910, train_clustering_loss:  0.5067, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6256, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 4 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 17, train_loss: 0.5824, train_clustering_loss:  0.4558, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6232, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 5 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 18, train_loss: 0.5806, train_clustering_loss:  0.4170, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6189, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.621754 --> 0.618860).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 19, train_loss: 0.5895, train_clustering_loss:  0.3803, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6134, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.618860 --> 0.613365).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 20, train_loss: 0.5879, train_clustering_loss:  0.3606, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6154, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 21, train_loss: 0.5787, train_clustering_loss:  0.3267, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6122, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.613365 --> 0.612154).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 22, train_loss: 0.5800, train_clustering_loss:  0.3058, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6124, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 23, train_loss: 0.5870, train_clustering_loss:  0.2729, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6152, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 24, train_loss: 0.5790, train_clustering_loss:  0.2636, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6063, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.612154 --> 0.606320).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 25, train_loss: 0.5748, train_clustering_loss:  0.2424, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6016, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.606320 --> 0.601640).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 26, train_loss: 0.5729, train_clustering_loss:  0.2278, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.6004, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.601640 --> 0.600360).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 27, train_loss: 0.5701, train_clustering_loss:  0.2050, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.5994, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.600360 --> 0.599439).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 28, train_loss: 0.5637, train_clustering_loss:  0.1974, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.5933, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.599439 --> 0.593280).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 29, train_loss: 0.5584, train_clustering_loss:  0.1764, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.5872, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.593280 --> 0.587215).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 30, train_loss: 0.5559, train_clustering_loss:  0.1686, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.5797, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.587215 --> 0.579721).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 31, train_loss: 0.5653, train_clustering_loss:  0.1735, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.5680, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.579721 --> 0.568022).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 32, train_loss: 0.5461, train_clustering_loss:  0.1552, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.5630, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.568022 --> 0.563001).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 33, train_loss: 0.5415, train_clustering_loss:  0.1502, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.5617, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.563001 --> 0.561747).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 34, train_loss: 0.5506, train_clustering_loss:  0.1552, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.5420, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.561747 --> 0.541964).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 35, train_loss: 0.5164, train_clustering_loss:  0.1714, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.5405, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.541964 --> 0.540512).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 36, train_loss: 0.4894, train_clustering_loss:  0.2028, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.5276, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.540512 --> 0.527620).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 0.9464285714285714: correct 53/56\n",
            "Epoch: 37, train_loss: 0.4942, train_clustering_loss:  0.2835, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.5110, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.527620 --> 0.510953).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 38, train_loss: 0.4461, train_clustering_loss:  0.2837, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.5056, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.510953 --> 0.505575).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 0.9642857142857143: correct 54/56\n",
            "Epoch: 39, train_loss: 0.4157, train_clustering_loss:  0.3164, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.5153, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 40, train_loss: 0.4012, train_clustering_loss:  0.2769, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.4772, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "Validation loss decreased (0.505575 --> 0.477182).  Saving model ...\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 41, train_loss: 0.3605, train_clustering_loss:  0.2790, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.5539, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 1 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 42, train_loss: 0.3199, train_clustering_loss:  0.2459, train_error: 0.2857\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 0.5777, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 2 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 0.9642857142857143: correct 54/56\n",
            "Epoch: 43, train_loss: 0.2890, train_clustering_loss:  0.2824, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.5202, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 3 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 0.9821428571428571: correct 55/56\n",
            "Epoch: 44, train_loss: 0.2634, train_clustering_loss:  0.2799, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.5071, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 4 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 45, train_loss: 0.2390, train_clustering_loss:  0.2502, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.6355, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 5 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 46, train_loss: 0.2264, train_clustering_loss:  0.2477, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.6903, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 6 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 47, train_loss: 0.2038, train_clustering_loss:  0.2139, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.7575, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 7 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 0.9821428571428571: correct 55/56\n",
            "Epoch: 48, train_loss: 0.1942, train_clustering_loss:  0.2330, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.7866, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 8 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 49, train_loss: 0.1487, train_clustering_loss:  0.2254, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.8222, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 9 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 0.9821428571428571: correct 55/56\n",
            "Epoch: 50, train_loss: 0.1609, train_clustering_loss:  0.2039, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.8542, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 10 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 51, train_loss: 0.1537, train_clustering_loss:  0.1558, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.8709, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 11 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 52, train_loss: 0.1289, train_clustering_loss:  0.1713, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.9142, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 12 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 53, train_loss: 0.1194, train_clustering_loss:  0.1786, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.9542, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 13 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 54, train_loss: 0.1100, train_clustering_loss:  0.1491, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.9684, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 14 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 55, train_loss: 0.1230, train_clustering_loss:  0.1443, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.9788, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 15 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 56, train_loss: 0.1060, train_clustering_loss:  0.1365, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.0254, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 16 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 57, train_loss: 0.0963, train_clustering_loss:  0.1380, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.0351, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 17 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 58, train_loss: 0.0832, train_clustering_loss:  0.1317, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.0670, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 18 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 59, train_loss: 0.0922, train_clustering_loss:  0.1176, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.0945, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 19 out of 20\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 56/56\n",
            "class 1 clustering acc 1.0: correct 56/56\n",
            "Epoch: 60, train_loss: 0.0681, train_clustering_loss:  0.0991, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.1356, val_error: 0.3333, auc: 1.0000\n",
            "class 0 clustering acc 1.0: correct 24/24\n",
            "class 1 clustering acc 1.0: correct 24/24\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "EarlyStopping counter: 20 out of 20\n",
            "Early stopping\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Val error: 0.3333, ROC AUC: 1.0000\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Test error: 0.3333, ROC AUC: 0.5000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "finished!\n",
            "end script\n"
          ]
        }
      ],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python main.py --label_frac 0.6 --drop_out 0.25 --early_stopping --lr 2e-4 --k 2 --exp_code task_1_tumor_vs_normal  --bag_loss ce --inst_loss svm --task task_1_tumor_vs_normal --model_type clam_sb --log_data --data_root_dir DATA_ROOT_DIR --embed_dim 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voejyOFZVwAH",
        "outputId": "f6083d44-5909-4f88-b8a9-3f0c5e1b4512"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'task': 'task_1_tumor_vs_normal', 'split': 'test', 'save_dir': './eval_results/EVAL_task_1_tumor_vs_normal_cv', 'models_dir': 'results/task_1_tumor_vs_normal_s1', 'model_type': 'clam_sb', 'drop_out': 0.25, 'model_size': 'small'}\n",
            "label column: label\n",
            "label dictionary: {'normal_tissue': 0, 'tumor_tissue': 1}\n",
            "number of classes: 2\n",
            "slide-level counts:  \n",
            " label\n",
            "1     4\n",
            "0    10\n",
            "Name: count, dtype: int64\n",
            "Patient-LVL; Number of samples registered in class 0: 5\n",
            "Slide-LVL; Number of samples registered in class 0: 10\n",
            "Patient-LVL; Number of samples registered in class 1: 4\n",
            "Slide-LVL; Number of samples registered in class 1: 4\n",
            "Init Model\n",
            "CLAM_SB(\n",
            "  (attention_net): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.25, inplace=False)\n",
            "    (3): Attn_Net_Gated(\n",
            "      (attention_a): Sequential(\n",
            "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "        (1): Tanh()\n",
            "        (2): Dropout(p=0.25, inplace=False)\n",
            "      )\n",
            "      (attention_b): Sequential(\n",
            "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "        (1): Sigmoid()\n",
            "        (2): Dropout(p=0.25, inplace=False)\n",
            "      )\n",
            "      (attention_c): Linear(in_features=256, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (classifiers): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (instance_classifiers): ModuleList(\n",
            "    (0-1): 2 x Linear(in_features=512, out_features=2, bias=True)\n",
            "  )\n",
            "  (instance_loss_fn): CrossEntropyLoss()\n",
            ")\n",
            "Total number of parameters: 790791\n",
            "Total number of trainable parameters: 790791\n",
            "Init Loaders\n",
            "test_error:  0.25\n",
            "auc:  1.0\n",
            "Init Model\n",
            "CLAM_SB(\n",
            "  (attention_net): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.25, inplace=False)\n",
            "    (3): Attn_Net_Gated(\n",
            "      (attention_a): Sequential(\n",
            "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "        (1): Tanh()\n",
            "        (2): Dropout(p=0.25, inplace=False)\n",
            "      )\n",
            "      (attention_b): Sequential(\n",
            "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "        (1): Sigmoid()\n",
            "        (2): Dropout(p=0.25, inplace=False)\n",
            "      )\n",
            "      (attention_c): Linear(in_features=256, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (classifiers): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (instance_classifiers): ModuleList(\n",
            "    (0-1): 2 x Linear(in_features=512, out_features=2, bias=True)\n",
            "  )\n",
            "  (instance_loss_fn): CrossEntropyLoss()\n",
            ")\n",
            "Total number of parameters: 790791\n",
            "Total number of trainable parameters: 790791\n",
            "Init Loaders\n",
            "test_error:  0.3333333333333333\n",
            "auc:  0.5\n"
          ]
        }
      ],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python eval.py --k 2 --models_exp_code task_1_tumor_vs_normal_s1 --save_exp_code task_1_tumor_vs_normal_cv --task task_1_tumor_vs_normal --model_type clam_sb --results_dir results --data_root_dir DATA_ROOT_DIR --embed_dim 1024\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P66S6Roj2eu9",
        "outputId": "e4a6abc2-e9dd-4b8e-ddc2-210976cd9330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "exp_arguments\n",
            "n_classes : 2\n",
            "save_exp_code : HEATMAP_OUTPUT\n",
            "raw_save_dir : heatmaps/heatmap_raw_results\n",
            "production_save_dir : heatmaps/heatmap_production_results\n",
            "batch_size : 256\n",
            "\n",
            "data_arguments\n",
            "data_dir : heatmaps/demo/slides/\n",
            "data_dir_key : source\n",
            "process_list : heatmap_demo_dataset.csv\n",
            "preset : presets/bwh_biopsy.csv\n",
            "slide_ext : .svs\n",
            "label_dict : {'LUAD': 0, 'LSCC': 1}\n",
            "\n",
            "patching_arguments\n",
            "patch_size : 256\n",
            "overlap : 0.5\n",
            "patch_level : 0\n",
            "custom_downsample : 1\n",
            "\n",
            "encoder_arguments\n",
            "model_name : resnet50_trunc\n",
            "target_img_size : 224\n",
            "\n",
            "model_arguments\n",
            "ckpt_path : heatmaps/demo/ckpts/s_0_checkpoint.pt\n",
            "model_type : clam_sb\n",
            "initiate_fn : initiate_model\n",
            "model_size : small\n",
            "drop_out : 0.0\n",
            "embed_dim : 1024\n",
            "\n",
            "heatmap_arguments\n",
            "vis_level : 1\n",
            "alpha : 0.4\n",
            "blank_canvas : False\n",
            "save_orig : True\n",
            "save_ext : jpg\n",
            "use_ref_scores : True\n",
            "blur : False\n",
            "use_center_shift : True\n",
            "use_roi : False\n",
            "calc_heatmap : True\n",
            "binarize : False\n",
            "binary_thresh : -1\n",
            "custom_downsample : 1\n",
            "cmap : jet\n",
            "\n",
            "sample_arguments\n",
            "samples : [{'name': 'topk_high_attention', 'sample': True, 'seed': 1, 'k': 15, 'mode': 'topk'}]\n",
            "Continue? Y/N Y\n",
            "patch_size: 256 x 256, with 0.50 overlap, step size is 128 x 128\n",
            "\n",
            "list of slides to process: \n",
            "       slide_id label  process status  ...  vis_level  line_thickness  use_padding  contour_fn\n",
            "0  C3L-03262-22  LUAD        1    tbp  ...         -1              50         True     four_pt\n",
            "1  C3L-01663-21  LSCC        1    tbp  ...         -1              50         True     four_pt\n",
            "\n",
            "[2 rows x 18 columns]\n",
            "\n",
            "initializing model from checkpoint\n",
            "\n",
            "ckpt path: heatmaps/demo/ckpts/s_0_checkpoint.pt\n",
            "Init Model\n",
            "CLAM_SB(\n",
            "  (attention_net): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.0, inplace=False)\n",
            "    (3): Attn_Net_Gated(\n",
            "      (attention_a): Sequential(\n",
            "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "        (1): Tanh()\n",
            "      )\n",
            "      (attention_b): Sequential(\n",
            "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "        (1): Sigmoid()\n",
            "      )\n",
            "      (attention_c): Linear(in_features=256, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (classifiers): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (instance_classifiers): ModuleList(\n",
            "    (0-1): 2 x Linear(in_features=512, out_features=2, bias=True)\n",
            "  )\n",
            "  (instance_loss_fn): CrossEntropyLoss()\n",
            ")\n",
            "Total number of parameters: 790791\n",
            "Total number of trainable parameters: 790791\n",
            "loading model checkpoint\n",
            "TimmCNNEncoder(\n",
            "  (model): FeatureListNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (act1): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act1): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (drop_block): Identity()\n",
            "        (act2): ReLU(inplace=True)\n",
            "        (aa): Identity()\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pool): AdaptiveAvgPool2d(output_size=1)\n",
            ")\n",
            "Done!\n",
            "  0% 0/2 [00:00<?, ?it/s]\n",
            "processing:  C3L-03262-22.svs\n",
            "slide id:  C3L-03262-22\n",
            "top left:  None  bot right:  None\n",
            "seg_level: -1\n",
            "sthresh: 15\n",
            "mthresh: 11\n",
            "close: 2\n",
            "use_otsu: False\n",
            "keep_ids: []\n",
            "exclude_ids: []\n",
            "a_t: 1\n",
            "a_h: 1\n",
            "max_n_holes: 2\n",
            "vis_level: -1\n",
            "line_thickness: 50\n",
            "Initializing WSI object\n",
            "Done!\n",
            "Y_hat: LUAD, Y: LUAD, Y_prob: ['0.9974', '0.0026']\n",
            "sampling topk_high_attention\n",
            "coord: [5988 4676] score: 100.000\n",
            "coord: [4964 5444] score: 99.487\n",
            "coord: [5732 3396] score: 98.974\n",
            "coord: [4964 5188] score: 98.462\n",
            "coord: [4964 3908] score: 97.949\n",
            "coord: [5732 3908] score: 97.436\n",
            "coord: [3172 4420] score: 96.923\n",
            "coord: [3684 3396] score: 96.410\n",
            "coord: [4964 4164] score: 95.897\n",
            "coord: [5988 3396] score: 95.385\n",
            "coord: [5988 4932] score: 94.872\n",
            "coord: [6244 4676] score: 94.359\n",
            "coord: [3172 3908] score: 93.846\n",
            "coord: [5476 4420] score: 93.333\n",
            "coord: [3172 3652] score: 92.821\n",
            "\n",
            "creating heatmap for: \n",
            "top_left:  (0, 0) bot_right:  (9959, 9023)\n",
            "w: 2489, h: 2255\n",
            "scaled patch size:  [64 64]\n",
            "\n",
            "computing foreground tissue mask\n",
            "detected 899730/5612695 of region as tissue\n",
            "\n",
            "computing heatmap image\n",
            "total of 195 patches\n",
            "progress: 38/195\n",
            "progress: 77/195\n",
            "progress: 116/195\n",
            "progress: 155/195\n",
            "progress: 194/195\n",
            "Done\n",
            "\n",
            "computing blend\n",
            "using block size: 1024 x 1024\n",
            "processing 0/2 contours\n",
            "Bounding Box: 5681 6038 1842 1077\n",
            "Contour Area: 628940.0\n",
            "Extracted 13 coordinates\n",
            "processing 1/2 contours\n",
            "Bounding Box: 2404 2884 4847 3951\n",
            "Contour Area: 13722139.0\n",
            "Extracted 760 coordinates\n",
            "filtered a total of 773 coordinates\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "total number of patches to process:  773\n",
            "number of batches:  4\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A/content/CLAM/utils/utils.py:37: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  label = torch.LongTensor([item[1] for item in batch])\n",
            "/content/CLAM/utils/utils.py:37: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  label = torch.LongTensor([item[1] for item in batch])\n",
            "/content/CLAM/utils/utils.py:37: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  label = torch.LongTensor([item[1] for item in batch])\n",
            "/content/CLAM/utils/utils.py:37: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  label = torch.LongTensor([item[1] for item in batch])\n",
            "  0% 0/4 [00:07<?, ?it/s]\n",
            "  0% 0/2 [00:11<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/CLAM/create_heatmaps.py\", line 369, in <module>\n",
            "    compute_from_patches(wsi_object=wsi_object, \n",
            "  File \"/content/CLAM/vis_utils/heatmap_utils.py\", line 80, in compute_from_patches\n",
            "    A[score_idx] = score2percentile(A[score_idx], ref_scores)\n",
            "ValueError: could not broadcast input array from shape (195,) into shape (1,)\n"
          ]
        }
      ],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python create_heatmaps.py --config config_template.yaml"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04732da1f3fb42f297fa1c6216552b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_76c9349cae63425e8eb6ee4ba54bdd05",
            "style": "IPY_MODEL_ed69754570e44424a62cdc2726fccdca",
            "value": true
          }
        },
        "05d2a5c046d04708a2872dc0f39eb6c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18ddab8bc4dc4f8fbba630eb9cefe3d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19b3bfde14d842fc9764a97ffd66b7c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e16caedc58d74ab6aa4abe6f9471f4b1",
              "IPY_MODEL_83e393b5a08d446cb08872a733acfc86",
              "IPY_MODEL_9a499bc57df94439affebade6d3bd22f",
              "IPY_MODEL_6449580c5ea34f2e96a40ce745648494"
            ],
            "layout": "IPY_MODEL_418f1ea87da843d3a1db7d8e76606f6b"
          }
        },
        "1ff7b7323be0431bae569584f0926391": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bc5f1af9e5b4d618c81477f793d66a8",
            "placeholder": "​",
            "style": "IPY_MODEL_429304bb15f74a5d9675d88e5a6d540d",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "246643b1249f4b7a9341e958a394a464": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_834fe0656cf64ef493da227b87e42c63",
            "placeholder": "​",
            "style": "IPY_MODEL_4141dce74a2f41ee914000447e20c521",
            "value": " 1.21G/1.21G [00:16&lt;00:00, 75.6MB/s]"
          }
        },
        "2608fe3a82d748baa06feccb930e2749": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30e92883186343b58176f489ac146298": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdf9b880ff5c4d05a151b6990acc23a9",
            "max": 1213527781,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b68d3637e39141f380e6af67f5a9fc6d",
            "value": 1213527781
          }
        },
        "3333f41853a649a5b71df87c8cb6b6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "374954057414425cbf0c2be9d7fead21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf38c04244e3420aac46eb951de7c46f",
            "placeholder": "​",
            "style": "IPY_MODEL_c9f3264a4aa645609da709e2762f291f",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "37912621793b418eabd754daf14a4553": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a26a6962fc5b4c2e852778cd68190549",
            "placeholder": "​",
            "style": "IPY_MODEL_3333f41853a649a5b71df87c8cb6b6d0",
            "value": "Connecting..."
          }
        },
        "4141dce74a2f41ee914000447e20c521": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "418f1ea87da843d3a1db7d8e76606f6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "429304bb15f74a5d9675d88e5a6d540d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49ceba181f11481eb98c2e5dcf69ee51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8413ab14f84840738138a648f9fa604a",
            "style": "IPY_MODEL_97d2eada0ffb4d5d9ebb16799ddc60f2",
            "tooltip": ""
          }
        },
        "4df74e5a5eda484391cfd792132a0955": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53b162fcd3ea496cac2930b6f52da71c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6449580c5ea34f2e96a40ce745648494": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e90bd251600f4ef7ac5a77dbe48584b0",
            "placeholder": "​",
            "style": "IPY_MODEL_4df74e5a5eda484391cfd792132a0955",
            "value": "Login successful"
          }
        },
        "76c9349cae63425e8eb6ee4ba54bdd05": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79f34794e0dd41e89223443b551d87b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "834fe0656cf64ef493da227b87e42c63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83e393b5a08d446cb08872a733acfc86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05d2a5c046d04708a2872dc0f39eb6c7",
            "placeholder": "​",
            "style": "IPY_MODEL_d8fb710672d2458789c7c2d1a9d60038",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "8413ab14f84840738138a648f9fa604a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97d2eada0ffb4d5d9ebb16799ddc60f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "9a499bc57df94439affebade6d3bd22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18ddab8bc4dc4f8fbba630eb9cefe3d0",
            "placeholder": "​",
            "style": "IPY_MODEL_79f34794e0dd41e89223443b551d87b2",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "9bc5f1af9e5b4d618c81477f793d66a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1b709a111794270b5c876a8931ab567": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_53b162fcd3ea496cac2930b6f52da71c",
            "placeholder": "​",
            "style": "IPY_MODEL_bb3172b0324747388c3457cb658c4710",
            "value": ""
          }
        },
        "a26a6962fc5b4c2e852778cd68190549": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac85b4e3835e4e8a9d6dbb4f1d15cb60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2ab21bdef484efc8e96696b47842be5",
              "IPY_MODEL_30e92883186343b58176f489ac146298",
              "IPY_MODEL_246643b1249f4b7a9341e958a394a464"
            ],
            "layout": "IPY_MODEL_ce30efab66c34b488067a25900fa3bc9"
          }
        },
        "b0fcda53b4bb4c15975a126e7c1f11ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b483aa232832487bbde5cb454f8aa6d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b68d3637e39141f380e6af67f5a9fc6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb3172b0324747388c3457cb658c4710": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdf9b880ff5c4d05a151b6990acc23a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf38c04244e3420aac46eb951de7c46f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1ca130f4b204a0ba37af3e2cc9bee61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2ab21bdef484efc8e96696b47842be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1ca130f4b204a0ba37af3e2cc9bee61",
            "placeholder": "​",
            "style": "IPY_MODEL_b0fcda53b4bb4c15975a126e7c1f11ab",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "c9f3264a4aa645609da709e2762f291f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce30efab66c34b488067a25900fa3bc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8fb710672d2458789c7c2d1a9d60038": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e16caedc58d74ab6aa4abe6f9471f4b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2608fe3a82d748baa06feccb930e2749",
            "placeholder": "​",
            "style": "IPY_MODEL_b483aa232832487bbde5cb454f8aa6d7",
            "value": "Token is valid (permission: fineGrained)."
          }
        },
        "e90bd251600f4ef7ac5a77dbe48584b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed69754570e44424a62cdc2726fccdca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
